% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictMC.R
\name{sampleEpisode}
\alias{sampleEpisode}
\title{Sample episode}
\usage{
sampleEpisode(policy, envir, initial.state, initial.action = NULL)
}
\arguments{
\item{policy}{a policy specified as a probability matrix (states x actions)}

\item{envir}{the environment, a function returning the next state and reward given an action}

\item{initial.state}{integer: the initial state}

\item{initial.action}{character: the initial action. Default is NULL,
then first action will be sampled from policy.}
}
\value{
a list with sampled actions, states and returns of the episode.
}
\description{
Sample an episode in an environment given a policy.
Note that this only works for episodic environments
(e.g. there must be at least one terminal state).
}
\examples{
set.seed(26)
grid = gridworld$new(shape = c(4, 4), terminal.states = c(1, 16))

# Define random policy
random.policy = matrix(1 / grid$n.actions, nrow = grid$n.states, 
  ncol = grid$n.actions)

# Sample an episode for the random.policy
episode = sampleEpisode(random.policy, grid, initial.state = 3)
print(episode$actions)
print(episode$rewards)
print(episode$states)

# Specify an initial action
grid$setEpisodeOverFalse()
episode = sampleEpisode(random.policy, grid, initial.state = 7, 
  initial.action = "right")
print(episode$actions)
print(episode$rewards)
print(episode$states)

}
