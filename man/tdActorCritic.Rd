% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/actorCritic.R
\name{tdActorCritic}
\alias{tdActorCritic}
\title{TD Actor Critic}
\usage{
tdActorCritic(envir, fun.approx = "table", policy = "softmax",
  preprocessState = identity, n.episodes = 100, discount = 1,
  alpha = 0.01, beta = 0.1, lambda = 0)
}
\description{
TD Actor Critic
}
\examples{
# Variant of cliff walking
library(reinforcelearn)
rewardFun = function(state, action, n.state) {
  if (n.state \%in\% 37:46) {
    return(- 100)
  } else {
    return(- 1)
  }
}
env = makeGridworld(shape = c(4, 12), goal.states = 47,
  cliff.states = 37:46, reward.step = - 1, reward.cliff = - 100,
  cliff.transition.done = TRUE, initial.state = 36, sampleReward = rewardFun)

tdActorCritic(env, n.episodes = 300)

}
