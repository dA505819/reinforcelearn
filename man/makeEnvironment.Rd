% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/makeEnvironment.R
\name{makeEnvironment}
\alias{makeEnvironment}
\title{Make Reinforcement Learning Environment}
\usage{
makeEnvironment(gym.envir.name, max.steps.episode = 200, ...)
}
\arguments{
\item{gym.envir.name}{scalar character, e.g. "FrozenLake-v0",
see \href{https://gym.openai.com/envs}{OpenAI Gym} for possible environments.}
}
\value{
Reinforcement Learning Environment, an R6 class.
}
\description{
State and action space can be either "Discrete" or "Box".
}
\section{Methods}{
 \describe{
\item{\code{envir$initialize()}}{Creates a new environment.}
\item{\code{envir$step(action, render = TRUE)}}{
Takes a step in the environment given an action,
returns the next state, reward and if episode is finished.
If render = TRUE the environment will be rendered.}
\item{\code{envir$reset()}}{Resets the
\code{episode.over} flag of the environment and returns an initial state.
Useful when starting a new episode.}
}
}

\examples{
\dontrun{
# Make sure you have gym-http-api and python installed.
# Then start a server from command line by running: python gym_http_server.py

FrozenLake = makeEnvironment("FrozenLake-v0")
FrozenLake$reset()
FrozenLake$step(action = 0)

# Now we can start a new FrozenLake environment by running:
FrozenLake$initialize()
}
}
\seealso{
\href{https://gym.openai.com/docs}{OpenAI Gym}
}
