% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictMC.R
\name{predictMC}
\alias{predictMC}
\title{Monte Carlo Prediction}
\usage{
predictMC(policy, envir, n.episodes = 10, discount.factor = 1,
  method = c("first-visit, every-visit"))
}
\arguments{
\item{policy}{a policy specified as a probability matrix [states x actions]}

\item{envir}{the environment, a function returning the next state and reward given an action}

\item{n.episodes}{integer: the number of episodes}

\item{discount.factor}{scalar numeric, discounting future rewards}

\item{method}{chacracter: first-visit or every-visit method}
}
\description{
Predict state value function with Monte Carlo methods
first.visit MC, evaluate given policy
}
\examples{
set.seed(1477)
grid = gridworld_R6$new()

# Define random policy
n.states = nrow(grid$reward.matrix)
n.actions = ncol(grid$reward.matrix)
random.policy = matrix(1 / n.actions, nrow = n.states, ncol = n.actions)

# Estimate state value function with Monte Carlo first visit prediction
v = predictMC(random.policy, grid, n.episodes = 10000, method = "first-visit")

# Compare results with expected result
v.expected = c(0, -14, -20, -22, -14, -18, -20, -20,
               -20, -20, -18, -14, -22, -20, -14, 0)
all.equal(v, v.expected, tolerance = 0.5)

}
