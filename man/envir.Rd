% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/envir.R
\name{envir}
\alias{envir}
\title{Creates environment}
\usage{
# env = envir(...)
# env$step(state, action)
}
\arguments{
\item{transition.array}{numerical matrix (n.states x n.states x n.actions)
for each action giving the probabilities for transitions from one state to
all other states}

\item{reward.matrix}{numerical matrix the rewards for transitions from one
state to another}

\item{terminal.states}{integer vector which states are terminal}
}
\value{
R6 class envir
}
\description{
This function creates an reinforcement learning environment from a given
transition.array and reward.matrix. The envir object is an R6 class with a
step method.
}
\section{Methods}{
 \describe{ \item{\code{envir$step(state,
  action)}}{Takes a step in the gridworld given a state and an action,
returns the next state and reward.}
\item{\code{envir$setEpisodeOverFalse()}}{Resets the
\code{episode.over} flag of the envir class. Useful when starting a new
episode.} }
}

\examples{
grid = gridworld$new()
env = envir(grid$transition.array, grid$reward.matrix, grid$terminal.states)
}
