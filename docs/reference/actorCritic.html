<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Actor Critic — actorCritic â€¢ reinforcelearn</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  
  
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/algorithms.html">How to solve an environment?</a>
    </li>
    <li>
      <a href="../articles/environments.html">How to create an environment?</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Actor Critic</h1>
    </div>

    
    <p>Policy-based reinforcement learning control algorithm using both policy (the actor)
and value function (the critic).</p>
    

    <pre class="usage"><span class='fu'>actorCritic</span>(<span class='no'>envir</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"table"</span>, <span class='kw'>policy</span> <span class='kw'>=</span> <span class='st'>"softmax"</span>,
  <span class='kw'>critic.type</span> <span class='kw'>=</span> <span class='st'>"advantage"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>identity</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>discount</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.01</span>, <span class='kw'>beta</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>lambda.actor</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>lambda.critic</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>updateAlpha</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateBeta</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLambdaActor</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateLambdaCritic</span> <span class='kw'>=</span> <span class='no'>identity2</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>envir</th>
      <td><p>[<code>R6 class</code>] 
The reinforcement learning environment created by <code><a href='makeEnvironment.html'>makeEnvironment</a></code>.</p></td>
    </tr>
    <tr>
      <th>fun.approx</th>
      <td><p>[<code>character(1)</code>] 
Type of function approximator used for policy and value function.
Currently supported are linear combination of features (<code>"linear"</code>) and
table lookup (<code>"table"</code>).</p></td>
    </tr>
    <tr>
      <th>policy</th>
      <td><p>[<code>character(1)</code>] 
Policy type, supported are <code>"softmax"</code> for a discrete action space and
<code>"gaussian"</code> for a continuous action space using a normal distribution.</p></td>
    </tr>
    <tr>
      <th>critic.type</th>
      <td><p>[<code>character(1)</code>] 
Type of the critic. Currently only an advantage actor critic is supported, which is
approximated by the td error.</p></td>
    </tr>
    <tr>
      <th>preprocessState</th>
      <td><p>[<code>function</code>] 
A function that takes the state observation returned from the environment as an input and
preprocesses this in a way the algorithm can work with it.</p></td>
    </tr>
    <tr>
      <th>n.episodes</th>
      <td><p>[<code>integer(1)</code>] 
Number of episodes.</p></td>
    </tr>
    <tr>
      <th>discount</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
Discount factor.</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>[<code>numeric(1)</code>] 
Learning rate (step size) for the policy.</p></td>
    </tr>
    <tr>
      <th>beta</th>
      <td><p>[<code>numeric(1)</code>] 
Learning rate (step size) for the critic.</p></td>
    </tr>
    <tr>
      <th>lambda.actor</th>
      <td><p>[<code>numeric(1)</code> in [0, 1]] 
Trace decay parameter for the actor.</p></td>
    </tr>
    <tr>
      <th>lambda.critic</th>
      <td><p>[<code>numeric(1)</code> in [0, 1]] 
Trace decay parameter for the critic.</p></td>
    </tr>
    <tr>
      <th>updateAlpha</th>
      <td><p>[<code>function</code>] 
A function which takes two arguments, <code>alpha</code> and the current number of episodes.
Could be used to decay the parameter over time.</p></td>
    </tr>
    <tr>
      <th>updateBeta</th>
      <td><p>[<code>function</code>] 
A function which takes two arguments, <code>beta</code> and the current number of episodes.
Could be used to decay the parameter over time.</p></td>
    </tr>
    <tr>
      <th>updateLambdaActor</th>
      <td><p>[<code>function</code>] 
A function which takes two arguments, <code>lambda.actor</code> and the current number of episodes.
Could be used to decay the parameter over time.</p></td>
    </tr>
    <tr>
      <th>updateLambdaCritic</th>
      <td><p>[<code>function</code>] 
A function which takes two arguments, <code>lambda.critic</code> and the current number of episodes.
Could be used to decay the parameter over time.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>[<code>list</code>] 
Returns a list with policy and value function parameters and
some statistics about learning behaviour, e.g. the number of
steps and return per episode.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>When using a gaussian policy mean and variance will be parametrized
as a linear combination of features mu = x * w_1 and sigma = exp(x * w_2).</p>
<p>For a softmax policy the action preferences are computed by a linear combination
of features.</p>
<p>Eligibility traces can be used for both policy parameters and value function parameters.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Sutton and Barto (Book draft 2017): Reinforcement Learning: An Introduction. Chapter 13</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># Mountain Car</span>
<span class='no'>m</span> <span class='kw'>=</span> <span class='fu'><a href='makeEnvironment.html'>makeEnvironment</a></span>(<span class='st'>"MountainCar"</span>)

<span class='co'># Define preprocessing function (we use grid tiling)</span>
<span class='no'>n.tilings</span> <span class='kw'>=</span> <span class='fl'>8</span>
<span class='no'>max.size</span> <span class='kw'>=</span> <span class='fl'>4096</span>
<span class='no'>iht</span> <span class='kw'>=</span> <span class='fu'><a href='tilecoding.html'>IHT</a></span>(<span class='no'>max.size</span>)

<span class='no'>position.max</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>1</span>]][<span class='fl'>2</span>]
<span class='no'>position.min</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>1</span>]][<span class='fl'>1</span>]
<span class='no'>velocity.max</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>2</span>]][<span class='fl'>2</span>]
<span class='no'>velocity.min</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>2</span>]][<span class='fl'>1</span>]
<span class='no'>position.scale</span> <span class='kw'>=</span> <span class='no'>n.tilings</span> / (<span class='no'>position.max</span> - <span class='no'>position.min</span>)
<span class='no'>velocity.scale</span> <span class='kw'>=</span> <span class='no'>n.tilings</span> / (<span class='no'>velocity.max</span> - <span class='no'>velocity.min</span>)

<span class='co'># Scale state first, then get active tiles and return n hot vector</span>
<span class='no'>gridTiling</span> <span class='kw'>=</span> <span class='kw'>function</span>(<span class='no'>state</span>) {
  <span class='no'>state</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='no'>position.scale</span> * <span class='no'>state</span>[<span class='fl'>1</span>], <span class='no'>velocity.scale</span> * <span class='no'>state</span>[<span class='fl'>2</span>])
  <span class='no'>active.tiles</span> <span class='kw'>=</span> <span class='fu'><a href='tilecoding.html'>tiles</a></span>(<span class='no'>iht</span>, <span class='fl'>8</span>, <span class='no'>state</span>)
  <span class='fu'><a href='nHot.html'>nHot</a></span>(<span class='no'>active.tiles</span>, <span class='no'>max.size</span>, <span class='kw'>out</span> <span class='kw'>=</span> <span class='st'>"vector"</span>)
}

<span class='co'># Linear function approximation and softmax policy</span>
<span class='no'>res</span> <span class='kw'>=</span> <span class='fu'>actorCritic</span>(<span class='no'>m</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"linear"</span>,
  <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>gridTiling</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>20</span>)</div><div class='output co'>#&gt; <span class='message'>Episode 1 finished after 1450 steps with a return of -1449</span></div><div class='output co'>#&gt; <span class='message'>Episode 2 finished after 327 steps with a return of -326</span></div><div class='output co'>#&gt; <span class='message'>Episode 3 finished after 290 steps with a return of -289</span></div><div class='output co'>#&gt; <span class='message'>Episode 4 finished after 235 steps with a return of -234</span></div><div class='output co'>#&gt; <span class='message'>Episode 5 finished after 233 steps with a return of -232</span></div><div class='output co'>#&gt; <span class='message'>Episode 6 finished after 277 steps with a return of -276</span></div><div class='output co'>#&gt; <span class='message'>Episode 7 finished after 236 steps with a return of -235</span></div><div class='output co'>#&gt; <span class='message'>Episode 8 finished after 256 steps with a return of -255</span></div><div class='output co'>#&gt; <span class='message'>Episode 9 finished after 155 steps with a return of -154</span></div><div class='output co'>#&gt; <span class='message'>Episode 10 finished after 152 steps with a return of -151</span></div><div class='output co'>#&gt; <span class='message'>Episode 11 finished after 187 steps with a return of -186</span></div><div class='output co'>#&gt; <span class='message'>Episode 12 finished after 191 steps with a return of -190</span></div><div class='output co'>#&gt; <span class='message'>Episode 13 finished after 157 steps with a return of -156</span></div><div class='output co'>#&gt; <span class='message'>Episode 14 finished after 162 steps with a return of -161</span></div><div class='output co'>#&gt; <span class='message'>Episode 15 finished after 204 steps with a return of -203</span></div><div class='output co'>#&gt; <span class='message'>Episode 16 finished after 199 steps with a return of -198</span></div><div class='output co'>#&gt; <span class='message'>Episode 17 finished after 153 steps with a return of -152</span></div><div class='output co'>#&gt; <span class='message'>Episode 18 finished after 155 steps with a return of -154</span></div><div class='output co'>#&gt; <span class='message'>Episode 19 finished after 151 steps with a return of -150</span></div><div class='output co'>#&gt; <span class='message'>Episode 20 finished after 146 steps with a return of -145</span></div><div class='input'>
<span class='co'>#----------------</span>
<span class='co'># Mountain Car with continuous action space</span>
<span class='no'>m</span> <span class='kw'>=</span> <span class='fu'><a href='makeEnvironment.html'>makeEnvironment</a></span>(<span class='st'>"MountainCarContinuous"</span>)

<span class='co'># Linear function approximation and gaussian policy</span>
<span class='fu'>set.seed</span>(<span class='fl'>123</span>)
<span class='no'>res</span> <span class='kw'>=</span> <span class='fu'>actorCritic</span>(<span class='no'>m</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"linear"</span>, <span class='kw'>policy</span> <span class='kw'>=</span> <span class='st'>"gaussian"</span>,
  <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>gridTiling</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>20</span>)</div><div class='output co'>#&gt; <span class='message'>Episode 1 finished after 780 steps with a return of -779</span></div><div class='output co'>#&gt; <span class='message'>Episode 2 finished after 319 steps with a return of -318</span></div><div class='output co'>#&gt; <span class='message'>Episode 3 finished after 317 steps with a return of -316</span></div><div class='output co'>#&gt; <span class='message'>Episode 4 finished after 157 steps with a return of -156</span></div><div class='output co'>#&gt; <span class='message'>Episode 5 finished after 149 steps with a return of -148</span></div><div class='output co'>#&gt; <span class='message'>Episode 6 finished after 194 steps with a return of -193</span></div><div class='output co'>#&gt; <span class='message'>Episode 7 finished after 153 steps with a return of -152</span></div><div class='output co'>#&gt; <span class='message'>Episode 8 finished after 132 steps with a return of -131</span></div><div class='output co'>#&gt; <span class='message'>Episode 9 finished after 106 steps with a return of -105</span></div><div class='output co'>#&gt; <span class='message'>Episode 10 finished after 151 steps with a return of -150</span></div><div class='output co'>#&gt; <span class='message'>Episode 11 finished after 106 steps with a return of -105</span></div><div class='output co'>#&gt; <span class='message'>Episode 12 finished after 136 steps with a return of -135</span></div><div class='output co'>#&gt; <span class='message'>Episode 13 finished after 110 steps with a return of -109</span></div><div class='output co'>#&gt; <span class='message'>Episode 14 finished after 98 steps with a return of -97</span></div><div class='output co'>#&gt; <span class='message'>Episode 15 finished after 96 steps with a return of -95</span></div><div class='output co'>#&gt; <span class='message'>Episode 16 finished after 101 steps with a return of -100</span></div><div class='output co'>#&gt; <span class='message'>Episode 17 finished after 144 steps with a return of -143</span></div><div class='output co'>#&gt; <span class='message'>Episode 18 finished after 96 steps with a return of -95</span></div><div class='output co'>#&gt; <span class='message'>Episode 19 finished after 103 steps with a return of -102</span></div><div class='output co'>#&gt; <span class='message'>Episode 20 finished after 165 steps with a return of -164</span></div><div class='input'>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
