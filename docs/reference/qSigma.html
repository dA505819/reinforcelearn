<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Q(sigma) / Q-Learning / Sarsa / Expected Sarsa — qSigma â€¢ reinforcelearn</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  
  
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/algorithms.html">How to solve an environment?</a>
    </li>
    <li>
      <a href="../articles/environments.html">How to create an environment?</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Q(sigma) / Q-Learning / Sarsa / Expected Sarsa</h1>
    </div>

    
    <p>Value-based reinforcement learning control algorithms.</p>
    

    <pre class="usage"><span class='fu'>qSigma</span>(<span class='no'>envir</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"table"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>identity</span>,
  <span class='kw'>model</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>initial.value</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.states</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>sigma</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>target.policy</span> <span class='kw'>=</span> <span class='st'>"egreedy"</span>, <span class='kw'>lambda</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>eligibility.type</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>learning.rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>0.1</span>,
  <span class='kw'>discount</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>double.learning</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>replay.memory</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>replay.memory.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>batch.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>theta</span> <span class='kw'>=</span> <span class='fl'>0.01</span>,
  <span class='kw'>updateEpsilon</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateSigma</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLambda</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateAlpha</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLearningRate</span> <span class='kw'>=</span> <span class='no'>identity2</span>)

<span class='fu'>qlearning</span>(<span class='no'>envir</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"table"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>identity</span>,
  <span class='kw'>model</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>initial.value</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.states</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>lambda</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>eligibility.type</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>learning.rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>0.1</span>,
  <span class='kw'>discount</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>double.learning</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>replay.memory</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>replay.memory.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>batch.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>theta</span> <span class='kw'>=</span> <span class='fl'>0.01</span>,
  <span class='kw'>updateEpsilon</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateSigma</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLambda</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateAlpha</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLearningRate</span> <span class='kw'>=</span> <span class='no'>identity2</span>)

<span class='fu'>sarsa</span>(<span class='no'>envir</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"table"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>identity</span>,
  <span class='kw'>model</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>initial.value</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.states</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>lambda</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>eligibility.type</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>learning.rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>0.1</span>,
  <span class='kw'>discount</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>double.learning</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>replay.memory</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>replay.memory.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>batch.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>theta</span> <span class='kw'>=</span> <span class='fl'>0.01</span>,
  <span class='kw'>updateEpsilon</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateSigma</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLambda</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateAlpha</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateLearningRate</span> <span class='kw'>=</span> <span class='no'>identity2</span>)

<span class='fu'>expectedSarsa</span>(<span class='no'>envir</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"table"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>identity</span>,
  <span class='kw'>model</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>initial.value</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.states</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>target.policy</span> <span class='kw'>=</span> <span class='st'>"egreedy"</span>, <span class='kw'>lambda</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>eligibility.type</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>learning.rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>discount</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>double.learning</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>replay.memory</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>replay.memory.size</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>batch.size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>theta</span> <span class='kw'>=</span> <span class='fl'>0.01</span>, <span class='kw'>updateEpsilon</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateSigma</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateLambda</span> <span class='kw'>=</span> <span class='no'>identity2</span>,
  <span class='kw'>updateAlpha</span> <span class='kw'>=</span> <span class='no'>identity2</span>, <span class='kw'>updateLearningRate</span> <span class='kw'>=</span> <span class='no'>identity2</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>envir</th>
      <td><p>[<code>R6 class</code>] 
The reinforcement learning environment created by <code><a href='makeEnvironment.html'>makeEnvironment</a></code>.</p></td>
    </tr>
    <tr>
      <th>fun.approx</th>
      <td><p>[<code>character(1)</code>] 
How to represent the value function? Currently <code>"table"</code> and <code>"linear"</code> are supported.</p></td>
    </tr>
    <tr>
      <th>preprocessState</th>
      <td><p>[<code>function</code>] 
A function that takes the state observation returned from the environment as an input and
preprocesses this in a way the algorithm can work with it.</p></td>
    </tr>
    <tr>
      <th>model</th>
      <td><p>[<code>any</code>] 
Currently unused parameter.</p></td>
    </tr>
    <tr>
      <th>initial.value</th>
      <td><p>[<code>numeric</code>] 
Initial value function matrix or weight matrix.
If <code>NULL</code> weights will be initialized to 0.
Only used for tabular or linear function approximation.</p></td>
    </tr>
    <tr>
      <th>n.states</th>
      <td><p>[<code>integer(1)</code>] 
Number of states for tabular value function.
Only needed if the state space is continuous, but
will be transformed by <code>preprocessState</code>, so that a single integer value is returned.
Else the number of states is accessed from the <code>envir$n.states</code> argument.</p></td>
    </tr>
    <tr>
      <th>n.episodes</th>
      <td><p>[<code>integer(1)</code>] 
Number of episodes.</p></td>
    </tr>
    <tr>
      <th>sigma</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
Parameter of the Q(sigma) algorithm. It controls if the temporal-difference target
is equal to the sarsa target (for <code>sigma = 1</code>) or the expected sarsa target
(for <code>sigma = 0</code>). For intermediate values of <code>sigma</code> a weighted mean
between the two targets is used.</p></td>
    </tr>
    <tr>
      <th>target.policy</th>
      <td><p>[<code>character(1)</code>] 
Should the expected sarsa target be computed on-policy
using the epsilon-greedy behavior policy (<code>target.policy = "egreedy"</code>)
or off-policy using a greedy target policy (<code>target.policy = "greedy"</code>)?</p></td>
    </tr>
    <tr>
      <th>lambda</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
Eligibility trace decay parameter.</p></td>
    </tr>
    <tr>
      <th>eligibility.type</th>
      <td><p>[<code>numeric(1)</code>] 
Type of eligibility trace, use <code>eligibility.type = 1</code> for replacing traces,
<code>eligibility.type = 0</code> for accumulating traces or
intermediate values for a mixture between both.</p></td>
    </tr>
    <tr>
      <th>learning.rate</th>
      <td><p>[<code>numeric(1)</code>] 
Learning rate used for gradient descent.</p></td>
    </tr>
    <tr>
      <th>epsilon</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
Ratio of random exploration in epsilon-greedy action selection.</p></td>
    </tr>
    <tr>
      <th>discount</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
Discount factor.</p></td>
    </tr>
    <tr>
      <th>double.learning</th>
      <td><p>[<code>logical(1)</code>] 
Should double learning be used?</p></td>
    </tr>
    <tr>
      <th>replay.memory</th>
      <td><p>[<code>list</code>] 
Initial replay memory, which can be passed on.
Each list element must be a list containing <code>state</code>, <code>action</code>,
<code>reward</code> and <code>next.state</code>.</p></td>
    </tr>
    <tr>
      <th>replay.memory.size</th>
      <td><p>[<code>integer(1)</code>] 
Size of the replay memory. Only used if <code>replay.memory</code> is <code>NULL</code>. Then
the replay memory will be initially filled with experiences following a uniform random policy.</p></td>
    </tr>
    <tr>
      <th>batch.size</th>
      <td><p>[<code>integer(1)</code>] 
Batch size, how many experiences are sampled from the replay memory at each step?
Must be smaller than the size of the replay memory!</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>[<code>numeric(1) in [0, 1]</code>] 
If <code>alpha = 0</code> sampling from the replay memory will be uniform,
otherwise observations with a high error will be proportionally prioritized.</p></td>
    </tr>
    <tr>
      <th>theta</th>
      <td><p>[<code>numeric(1) in (0, 1]</code>] 
<code>theta</code> is a small positive constant that prevents the edge-case of transitions
in the replay memory not being revisited once their error is zero.</p></td>
    </tr>
    <tr>
      <th>updateEpsilon</th>
      <td><p>[<code>function</code>] 
A function that updates <code>epsilon</code>. It takes two arguments,
<code>epsilon</code> and the current number of episodes which are finished,
and returns the new <code>epsilon</code> value.</p></td>
    </tr>
    <tr>
      <th>updateSigma</th>
      <td><p>[<code>function</code>] 
A function that updates <code>sigma</code>. It takes two arguments,
<code>sigma</code> and the current number of episodes which are finished,
and returns the new <code>sigma</code> value.</p></td>
    </tr>
    <tr>
      <th>updateLambda</th>
      <td><p>[<code>function</code>] 
A function that updates <code>lambda</code>. It takes two arguments,
<code>lambda</code> and the current number
of episodes which are finished, and returns the new <code>lambda</code> value.</p></td>
    </tr>
    <tr>
      <th>updateAlpha</th>
      <td><p>[<code>function</code>] 
A function that updates <code>alpha</code>. It takes two arguments,
<code>alpha</code> and the current number
of episodes which are finished, and returns the new <code>alpha</code> value.</p></td>
    </tr>
    <tr>
      <th>updateLearningRate</th>
      <td><p>[<code>function</code>] 
A function that updates the learning rate. It takes two arguments, <code>learning.rate</code>
and the current number of episodes which are finished, and returns the new
<code>learning.rate</code> value.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>[<code>list(4)</code>] 
  Returns the action value function or model parameters [<code>matrix</code>] and the
  return and number of steps per episode [<code>numeric</code>].
  For Double Learning both value functions will be returned.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Q(sigma), Q-Learning, Expected Sarsa and Sarsa build a family of temporal-difference learning
algorithms, which can be used to find the optimal action value function using the principle
of generalized policy iteration.
Q(sigma) subsumes Q-Learning, Sarsa and Expected Sarsa as special cases.
For more details on the algorithm read De Asis et al. (2017).
Expected Sarsa can be used on-policy if <code>target.policy == "egreedy"</code> else it is identical
to Q-Learning.</p>
<p>When <code>fun.approx == "table"</code> the action value function will be represented as a matrix,
but you can also use a linear combination of features for function approximation.</p>
<p>The raw state observation returned from the environment must be preprocessed using
the <code>preprocessState</code> argument. This function takes the state observation as input and
returns a preprocessed state which can be directly used by the function approximator.
To use a tabular value function <code>preprocessState</code> must return an integer value between
[0, number of states - 1]. For linear function approximation the output of
<code>preprocessState</code> must be a matrix with one row.</p>
<p>Experience replay can be used by specifying a prefilled replay memory using the
<code>replay.memory</code> argument or by specifying the length of the replay memory,
which is then filled with experience using a random uniform policy.
Sampling can also be prioritized by the error as proposed by Schaul et al. (2016).</p>
<p>Note that eligibility traces cannot be used with experience replay.</p>
<p>The hyperparameters <code>epsilon</code>, <code>sigma</code>, <code>alpha</code>, <code>lambda</code> and
<code>learning.rate</code> can be changed over time. Therefore pass on functions that return a new
value of the hyperparameter. These updates will be applied after each episode. First argument of
the function must be the parameter itself, the second argument the current episode number.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>De Asis et al. (2017): Multi-step Reinforcement Learning: A Unifying Algorithm</p>
<p>Hasselt et al. (2010): Double Q-Learning</p>
<p>Mnih et al. (2013): Playing Atari with Deep Reinforcement Learning</p>
<p>Schaul et al. (2016): Prioritized Experience Replay</p>
<p>Sutton and Barto (Book draft 2017): Reinforcement Learning: An Introduction</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># Solve Windy Gridworld</span>
<span class='no'>env</span> <span class='kw'>=</span> <span class='fu'><a href='makeEnvironment.html'>makeEnvironment</a></span>(<span class='st'>"WindyGridworld"</span>)

<span class='no'>res</span> <span class='kw'>=</span> <span class='fu'>qlearning</span>(<span class='no'>env</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>20</span>)</div><div class='output co'>#&gt; <span class='message'>Episode 1 finished after 854 steps with a return of -854</span></div><div class='output co'>#&gt; <span class='message'>Episode 2 finished after 1236 steps with a return of -1236</span></div><div class='output co'>#&gt; <span class='message'>Episode 3 finished after 1063 steps with a return of -1063</span></div><div class='output co'>#&gt; <span class='message'>Episode 4 finished after 367 steps with a return of -367</span></div><div class='output co'>#&gt; <span class='message'>Episode 5 finished after 427 steps with a return of -427</span></div><div class='output co'>#&gt; <span class='message'>Episode 6 finished after 357 steps with a return of -357</span></div><div class='output co'>#&gt; <span class='message'>Episode 7 finished after 103 steps with a return of -103</span></div><div class='output co'>#&gt; <span class='message'>Episode 8 finished after 424 steps with a return of -424</span></div><div class='output co'>#&gt; <span class='message'>Episode 9 finished after 261 steps with a return of -261</span></div><div class='output co'>#&gt; <span class='message'>Episode 10 finished after 251 steps with a return of -251</span></div><div class='output co'>#&gt; <span class='message'>Episode 11 finished after 230 steps with a return of -230</span></div><div class='output co'>#&gt; <span class='message'>Episode 12 finished after 226 steps with a return of -226</span></div><div class='output co'>#&gt; <span class='message'>Episode 13 finished after 141 steps with a return of -141</span></div><div class='output co'>#&gt; <span class='message'>Episode 14 finished after 112 steps with a return of -112</span></div><div class='output co'>#&gt; <span class='message'>Episode 15 finished after 169 steps with a return of -169</span></div><div class='output co'>#&gt; <span class='message'>Episode 16 finished after 161 steps with a return of -161</span></div><div class='output co'>#&gt; <span class='message'>Episode 17 finished after 287 steps with a return of -287</span></div><div class='output co'>#&gt; <span class='message'>Episode 18 finished after 106 steps with a return of -106</span></div><div class='output co'>#&gt; <span class='message'>Episode 19 finished after 79 steps with a return of -79</span></div><div class='output co'>#&gt; <span class='message'>Episode 20 finished after 35 steps with a return of -35</span></div><div class='input'><span class='fu'>print</span>(<span class='no'>res</span>$<span class='no'>steps</span>)</div><div class='output co'>#&gt;  [1]  854 1236 1063  367  427  357  103  424  261  251  230  226  141  112  169
#&gt; [16]  161  287  106   79   35</div><div class='input'>
<span class='co'># State value function</span>
<span class='fu'>print</span>(<span class='fu'>matrix</span>(<span class='fu'>round</span>(<span class='fu'>apply</span>(<span class='no'>res</span>$<span class='no'>Q1</span>, <span class='fl'>1</span>, <span class='no'>max</span>), <span class='fl'>1</span>), <span class='kw'>ncol</span> <span class='kw'>=</span> <span class='fl'>10</span>, <span class='kw'>byrow</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>))</div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
#&gt; [1,] -4.1 -4.3 -4.8 -5.6 -6.3 -6.7 -6.8 -6.3 -5.6  -4.8
#&gt; [2,] -3.9 -4.0 -4.1 -4.4 -4.1 -3.2 -1.9 -3.4 -4.0  -3.9
#&gt; [3,] -3.5 -3.5 -3.4 -3.3 -2.6 -1.1 -0.5 -1.7 -3.1  -3.1
#&gt; [4,] -3.3 -3.1 -2.8 -2.4 -1.3 -0.3 -0.1  0.0 -1.9  -2.3
#&gt; [5,] -2.8 -2.6 -2.2 -1.7 -0.7 -0.2  0.0 -0.2 -0.8  -1.6
#&gt; [6,] -2.4 -2.1 -1.7 -1.2 -0.4  0.0  0.0  0.0 -0.5  -0.9
#&gt; [7,] -2.1 -1.9 -1.4 -0.7  0.0  0.0  0.0  0.0 -0.1  -0.5</div><div class='input'>
<span class='co'># Policy</span>
<span class='no'>policy</span> <span class='kw'>=</span> <span class='fu'>max.col</span>(<span class='no'>res</span>$<span class='no'>Q1</span>) - <span class='fl'>1L</span>
<span class='fu'>print</span>(<span class='fu'>matrix</span>(<span class='no'>policy</span>, <span class='kw'>ncol</span> <span class='kw'>=</span> <span class='fl'>10</span>, <span class='kw'>byrow</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>))</div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
#&gt; [1,]    0    1    0    0    3    0    3    2    1     3
#&gt; [2,]    3    0    2    0    3    3    3    3    3     3
#&gt; [3,]    3    0    2    0    0    3    1    1    0     3
#&gt; [4,]    3    3    2    0    1    0    3    1    3     3
#&gt; [5,]    3    0    0    1    1    2    1    3    0     3
#&gt; [6,]    3    1    3    1    0    0    0    3    2     0
#&gt; [7,]    1    1    3    2    1    1    2    1    2     3</div><div class='input'>
<span class='co'># Decay epsilon over time. Each 10 episodes epsilon will be halfed.</span>
<span class='no'>decayEpsilon</span> <span class='kw'>=</span> <span class='kw'>function</span>(<span class='no'>epsilon</span>, <span class='no'>i</span>) {
  <span class='kw'>if</span> (<span class='no'>i</span> <span class='kw'>%%</span> <span class='fl'>10</span> <span class='kw'>==</span> <span class='fl'>0</span>) {
    <span class='no'>epsilon</span> <span class='kw'>=</span> <span class='no'>epsilon</span> * <span class='fl'>0.5</span>
  }
  <span class='no'>epsilon</span>
}

<span class='no'>res</span> <span class='kw'>=</span> <span class='fu'>expectedSarsa</span>(<span class='no'>env</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>0.5</span>, <span class='kw'>updateEpsilon</span> <span class='kw'>=</span> <span class='no'>decayEpsilon</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>20</span>)</div><div class='output co'>#&gt; <span class='message'>Episode 1 finished after 3351 steps with a return of -3351</span></div><div class='output co'>#&gt; <span class='message'>Episode 2 finished after 111 steps with a return of -111</span></div><div class='output co'>#&gt; <span class='message'>Episode 3 finished after 77 steps with a return of -77</span></div><div class='output co'>#&gt; <span class='message'>Episode 4 finished after 581 steps with a return of -581</span></div><div class='output co'>#&gt; <span class='message'>Episode 5 finished after 1746 steps with a return of -1746</span></div><div class='output co'>#&gt; <span class='message'>Episode 6 finished after 203 steps with a return of -203</span></div><div class='output co'>#&gt; <span class='message'>Episode 7 finished after 59 steps with a return of -59</span></div><div class='output co'>#&gt; <span class='message'>Episode 8 finished after 153 steps with a return of -153</span></div><div class='output co'>#&gt; <span class='message'>Episode 9 finished after 298 steps with a return of -298</span></div><div class='output co'>#&gt; <span class='message'>Episode 10 finished after 387 steps with a return of -387</span></div><div class='output co'>#&gt; <span class='message'>Episode 11 finished after 23 steps with a return of -23</span></div><div class='output co'>#&gt; <span class='message'>Episode 12 finished after 294 steps with a return of -294</span></div><div class='output co'>#&gt; <span class='message'>Episode 13 finished after 112 steps with a return of -112</span></div><div class='output co'>#&gt; <span class='message'>Episode 14 finished after 185 steps with a return of -185</span></div><div class='output co'>#&gt; <span class='message'>Episode 15 finished after 205 steps with a return of -205</span></div><div class='output co'>#&gt; <span class='message'>Episode 16 finished after 114 steps with a return of -114</span></div><div class='output co'>#&gt; <span class='message'>Episode 17 finished after 88 steps with a return of -88</span></div><div class='output co'>#&gt; <span class='message'>Episode 18 finished after 167 steps with a return of -167</span></div><div class='output co'>#&gt; <span class='message'>Episode 19 finished after 21 steps with a return of -21</span></div><div class='output co'>#&gt; <span class='message'>Episode 20 finished after 76 steps with a return of -76</span></div><div class='input'>
<span class='co'># Solve the Mountain Car problem using linear function approximation</span>
<span class='no'>m</span> <span class='kw'>=</span> <span class='fu'><a href='makeEnvironment.html'>makeEnvironment</a></span>(<span class='st'>"MountainCar"</span>)

<span class='co'># Define preprocessing function (we use grid tiling)</span>
<span class='no'>n.tilings</span> <span class='kw'>=</span> <span class='fl'>8</span>
<span class='no'>max.size</span> <span class='kw'>=</span> <span class='fl'>4096</span>
<span class='no'>iht</span> <span class='kw'>=</span> <span class='fu'><a href='tilecoding.html'>IHT</a></span>(<span class='no'>max.size</span>)

<span class='no'>position.max</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>1</span>]][<span class='fl'>2</span>]
<span class='no'>position.min</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>1</span>]][<span class='fl'>1</span>]
<span class='no'>velocity.max</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>2</span>]][<span class='fl'>2</span>]
<span class='no'>velocity.min</span> <span class='kw'>=</span> <span class='no'>m</span>$<span class='no'>state.space.bounds</span><span class='kw'>[[</span><span class='fl'>2</span>]][<span class='fl'>1</span>]
<span class='no'>position.scale</span> <span class='kw'>=</span> <span class='no'>n.tilings</span> / (<span class='no'>position.max</span> - <span class='no'>position.min</span>)
<span class='no'>velocity.scale</span> <span class='kw'>=</span> <span class='no'>n.tilings</span> / (<span class='no'>velocity.max</span> - <span class='no'>velocity.min</span>)

<span class='co'># Scale state first, then get active tiles and return n hot vector</span>
<span class='no'>gridTiling</span> <span class='kw'>=</span> <span class='kw'>function</span>(<span class='no'>state</span>) {
  <span class='no'>state</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='no'>position.scale</span> * <span class='no'>state</span>[<span class='fl'>1</span>], <span class='no'>velocity.scale</span> * <span class='no'>state</span>[<span class='fl'>2</span>])
  <span class='no'>active.tiles</span> <span class='kw'>=</span> <span class='fu'><a href='tilecoding.html'>tiles</a></span>(<span class='no'>iht</span>, <span class='fl'>8</span>, <span class='no'>state</span>)
  <span class='fu'><a href='nHot.html'>nHot</a></span>(<span class='no'>active.tiles</span>, <span class='no'>max.size</span>, <span class='kw'>out</span> <span class='kw'>=</span> <span class='st'>"vector"</span>)
}

<span class='fu'>set.seed</span>(<span class='fl'>123</span>)
<span class='no'>res</span> <span class='kw'>=</span> <span class='fu'>sarsa</span>(<span class='no'>m</span>, <span class='kw'>fun.approx</span> <span class='kw'>=</span> <span class='st'>"linear"</span>, <span class='kw'>preprocessState</span> <span class='kw'>=</span> <span class='no'>gridTiling</span>, <span class='kw'>n.episodes</span> <span class='kw'>=</span> <span class='fl'>20</span>)</div><div class='output co'>#&gt; <span class='message'>Episode 1 finished after 1036 steps with a return of -1035</span></div><div class='output co'>#&gt; <span class='message'>Episode 2 finished after 712 steps with a return of -711</span></div><div class='output co'>#&gt; <span class='message'>Episode 3 finished after 564 steps with a return of -563</span></div><div class='output co'>#&gt; <span class='message'>Episode 4 finished after 394 steps with a return of -393</span></div><div class='output co'>#&gt; <span class='message'>Episode 5 finished after 485 steps with a return of -484</span></div><div class='output co'>#&gt; <span class='message'>Episode 6 finished after 322 steps with a return of -321</span></div><div class='output co'>#&gt; <span class='message'>Episode 7 finished after 427 steps with a return of -426</span></div><div class='output co'>#&gt; <span class='message'>Episode 8 finished after 321 steps with a return of -320</span></div><div class='output co'>#&gt; <span class='message'>Episode 9 finished after 232 steps with a return of -231</span></div><div class='output co'>#&gt; <span class='message'>Episode 10 finished after 288 steps with a return of -287</span></div><div class='output co'>#&gt; <span class='message'>Episode 11 finished after 192 steps with a return of -191</span></div><div class='output co'>#&gt; <span class='message'>Episode 12 finished after 236 steps with a return of -235</span></div><div class='output co'>#&gt; <span class='message'>Episode 13 finished after 302 steps with a return of -301</span></div><div class='output co'>#&gt; <span class='message'>Episode 14 finished after 234 steps with a return of -233</span></div><div class='output co'>#&gt; <span class='message'>Episode 15 finished after 198 steps with a return of -197</span></div><div class='output co'>#&gt; <span class='message'>Episode 16 finished after 198 steps with a return of -197</span></div><div class='output co'>#&gt; <span class='message'>Episode 17 finished after 249 steps with a return of -248</span></div><div class='output co'>#&gt; <span class='message'>Episode 18 finished after 317 steps with a return of -316</span></div><div class='output co'>#&gt; <span class='message'>Episode 19 finished after 258 steps with a return of -257</span></div><div class='output co'>#&gt; <span class='message'>Episode 20 finished after 241 steps with a return of -240</span></div><div class='input'><span class='fu'>print</span>(<span class='no'>res</span>$<span class='no'>returns</span>)</div><div class='output co'>#&gt;  [1] -1035  -711  -563  -393  -484  -321  -426  -320  -231  -287  -191  -235
#&gt; [13]  -301  -233  -197  -197  -248  -316  -257  -240</div><div class='input'>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
