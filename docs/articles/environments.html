<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Environments • reinforcelearn</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/environments.html">Environments</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Environments</h1>
                        <h4 class="author">Markus Dumke</h4>
            
            <h4 class="date">2017-12-21</h4>
          </div>

    
    
<div class="contents">
<style type="text/css">
  h1.title {
  font-size: 34px;
  }
</style>
<p>This vignette explains the different possibilities to create and use a reinforcement learning environment in <code>reinforcelearn</code>. Section <a href="#creation">Creation</a> explains how to create an environment and Section <a href="#interaction">Interaction</a> describe how to use the created environment object for interaction.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reinforcelearn)</code></pre></div>
<div id="creation" class="section level2">
<h2 class="hasAnchor">
<a href="#creation" class="anchor"></a>Creation</h2>
<p>The <code>makeEnvironment</code> function provides different ways to create an environment. It is called with the class name as a first argument. You can pass arguments of the specific environment class (e.g. the state transition array for an MDP) to the <code>...</code> argument.</p>
<div id="create-a-custom-environment" class="section level3">
<h3 class="hasAnchor">
<a href="#create-a-custom-environment" class="anchor"></a>Create a custom environment</h3>
<p>To create a custom environment you have to set up a <code>step</code> and <code>reset</code> function, which define the rewards the agent receives and ultimately the goal of what to learn.</p>
<p>Here is an example setting up a the famous Mountain Car problem.</p>
<p><img src="mountaincar.JPG" width="200px" style="display: block; margin: auto;"></p>
<p>The task of the <code>reset</code> function is to initialize the starting state of the environment and usually this function is called when starting a new episode. It returns the <code>state</code> of the environment. It takes an argument <code>self</code>, which is the newly created R6 class and can be used e.g. to access the current state of the environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reset =<span class="st"> </span><span class="cf">function</span>(self) {
  position =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="op">-</span><span class="fl">0.6</span>, <span class="op">-</span><span class="fl">0.4</span>)
  velocity =<span class="st"> </span><span class="dv">0</span>
  state =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(position, velocity), <span class="dt">ncol =</span> <span class="dv">2</span>)
  state
}</code></pre></div>
<p>The <code>step</code> function is used for interaction, it controls the transition to the next state and reward given an action. It takes <code>self</code> and <code>action</code> as an argument and returns a list with the next <code>state</code>, <code>reward</code> and whether an episode is finished (<code>done</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">step =<span class="st"> </span><span class="cf">function</span>(self, action) {
  position =<span class="st"> </span>self<span class="op">$</span>state[<span class="dv">1</span>]
  velocity =<span class="st"> </span>self<span class="op">$</span>state[<span class="dv">2</span>]
  velocity =<span class="st"> </span>(action <span class="op">-</span><span class="st"> </span>1L) <span class="op">*</span><span class="st"> </span><span class="fl">0.001</span> <span class="op">+</span><span class="st"> </span><span class="kw">cos</span>(<span class="dv">3</span> <span class="op">*</span><span class="st"> </span>position) <span class="op">*</span><span class="st"> </span>(<span class="op">-</span><span class="fl">0.0025</span>)
  velocity =<span class="st"> </span><span class="kw">min</span>(<span class="kw">max</span>(velocity, <span class="op">-</span><span class="fl">0.07</span>), <span class="fl">0.07</span>)
  position =<span class="st"> </span>position <span class="op">+</span><span class="st"> </span>velocity
  <span class="cf">if</span> (position <span class="op">&lt;</span><span class="st"> </span><span class="op">-</span><span class="fl">1.2</span>) {
    position =<span class="st"> </span><span class="op">-</span><span class="fl">1.2</span>
    velocity =<span class="st"> </span><span class="dv">0</span>
  }
  state =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(position, velocity), <span class="dt">ncol =</span> <span class="dv">2</span>)
  reward =<span class="st"> </span><span class="op">-</span><span class="dv">1</span>
  <span class="cf">if</span> (position <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>) {
    done =<span class="st"> </span><span class="ot">TRUE</span>
    reward =<span class="st"> </span><span class="dv">0</span>
  } <span class="cf">else</span> {
    done =<span class="st"> </span><span class="ot">FALSE</span>
  }
  <span class="kw">list</span>(state, reward, done)
}</code></pre></div>
<p>Then we can create the environment with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="dt">step =</span> step, <span class="dt">reset =</span> reset)</code></pre></div>
<hr>
</div>
<div id="openai-gym" class="section level3">
<h3 class="hasAnchor">
<a href="#openai-gym" class="anchor"></a>OpenAI Gym</h3>
<p>OpenAI Gym <span class="citation">(Brockman et al. 2016)</span> provides a set of environments, which can be used for benchmarking.</p>
<p>To use a gym environment you have to install</p>
<ul>
<li>Python</li>
<li>
<code>gym</code> (Python package, installation instructions here: <a href="https://github.com/openai/gym#installation" class="uri">https://github.com/openai/gym#installation</a>)</li>
<li>
<code>reticulate</code> (R package)</li>
</ul>
<p>Then you can create a gym environment by passing on the name of the environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a gym environment.</span>
env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gym"</span>, <span class="st">"MountainCar-v0"</span>)</code></pre></div>
<p>Have a look at <a href="https://gym.openai.com/envs" class="uri">https://gym.openai.com/envs</a> for possible environments.</p>
<hr>
</div>
<div id="markov-decision-process" class="section level3">
<h3 class="hasAnchor">
<a href="#markov-decision-process" class="anchor"></a>Markov Decision Process</h3>
<p>A Markov Decision Process (MDP) is a stochastic process, which is commonly used for reinforcement learning environments. When the problem can be formulated as a MDP, all you need to pass to <code>makeEnvironment</code> is the state transition array <span class="math inline">\(P^a_{ss'}\)</span> and reward matrix <span class="math inline">\(R_s^a\)</span> of the MDP.</p>
<p>We can create a simple MDP with 2 states and 2 actions with the following code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># State transition array</span>
P =<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))
P[, , <span class="dv">1</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
P[, , <span class="dv">2</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)

<span class="co"># Reward matrix</span>
R =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)

env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"mdp"</span>, <span class="dt">transitions =</span> P, <span class="dt">rewards =</span> R)</code></pre></div>
<hr>
</div>
<div id="gridworld" class="section level3">
<h3 class="hasAnchor">
<a href="#gridworld" class="anchor"></a>Gridworld</h3>
<p>A gridworld is a simple MDP navigation task with a discrete state and action space. The agent has to move through a grid from a start state to a goal state. Possible actions are the standard moves (left, right, up, down) or could also include the diagonal moves (leftup, leftdown, rightup, rightdown).</p>
<p>Here is an example of a 4x4 gridworld <span class="citation">(Sutton and Barto 2017, Example 4.1)</span> with two terminal states in the lower right and upper left of the grid. Rewards are - 1 for every transition until reaching a terminal state.</p>
<p><img src="gridworld.JPG" width="200px" style="display: block; margin: auto;"></p>
<p>The following code creates this gridworld.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Gridworld Environment (Sutton &amp; Barto (2017) Example 4.1)</span>
env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>), <span class="dt">goal.states =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">15</span>))</code></pre></div>
<hr>
</div>
</div>
<div id="interaction" class="section level2">
<h2 class="hasAnchor">
<a href="#interaction" class="anchor"></a>Interaction</h2>
<p><code>makeEnvironment</code> returns an R6 class object which can be used for the interaction between agent and environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>), 
  <span class="dt">goal.states =</span> 0L, <span class="dt">initial.state =</span> 15L)</code></pre></div>
<p>To take an action you can call the <code>step(action)</code> method. It is called with an action as an argument and internally computes the following <code>state</code>, <code>reward</code> and whether an episode is finished (<code>done</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The initial state of the environment.</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="co">#&gt; [1] 15</span>

env<span class="op">$</span><span class="kw">visualize</span>()
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - o</span>

<span class="co"># Actions are encoded as integers.</span>
env<span class="op">$</span><span class="kw">step</span>(0L)
<span class="co">#&gt; $state</span>
<span class="co">#&gt; [1] 14</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $done</span>
<span class="co">#&gt; [1] FALSE</span>

env<span class="op">$</span><span class="kw">visualize</span>()
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - o -</span>

<span class="co"># But can also have character names.</span>
env<span class="op">$</span><span class="kw">step</span>(<span class="st">"left"</span>)
<span class="co">#&gt; $state</span>
<span class="co">#&gt; [1] 13</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $done</span>
<span class="co">#&gt; [1] FALSE</span>

env<span class="op">$</span><span class="kw">visualize</span>()
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - o - -</span></code></pre></div>
<p>Note that the R6 class object changes whenever calling <code>step</code> or <code>reset</code>! Therefore calling step with the same action twice will most likely return different states and rewards!</p>
<p>Note also that all discrete states and actions are numerated starting with 0 to be consistent with OpenAI Gym!</p>
<p>The environment object often also contains information about the number of states and actions or the bounds in case of a continuous space.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"mountain.car"</span>)
env<span class="op">$</span>n.actions
<span class="co">#&gt; [1] 3</span>
env<span class="op">$</span>state.space.bounds
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; [1] -1.2  0.5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; [1] -0.07  0.07</span></code></pre></div>
<p>It also contains a counter of the number of interactions, i.e. the number of times <code>step</code> has been called, the number of steps in the current episode, the number of episodes and return in the current episode.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>), 
  <span class="dt">goal.states =</span> 0L, <span class="dt">initial.state =</span> 15L, <span class="dt">discount =</span> <span class="fl">0.99</span>)

env<span class="op">$</span><span class="kw">step</span>(<span class="st">"up"</span>)
<span class="co">#&gt; $state</span>
<span class="co">#&gt; [1] 11</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $done</span>
<span class="co">#&gt; [1] FALSE</span>
env<span class="op">$</span>n.step
<span class="co">#&gt; [1] 1</span>
env<span class="op">$</span>episode.return
<span class="co">#&gt; [1] -1</span>

env<span class="op">$</span><span class="kw">step</span>(<span class="st">"left"</span>)
<span class="co">#&gt; $state</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $done</span>
<span class="co">#&gt; [1] FALSE</span>
env<span class="op">$</span>n.step
<span class="co">#&gt; [1] 2</span>
env<span class="op">$</span>episode.return
<span class="co">#&gt; [1] -1.99</span></code></pre></div>
<hr>
<div id="full-list-of-attributes-and-methods" class="section level3">
<h3 class="hasAnchor">
<a href="#full-list-of-attributes-and-methods" class="anchor"></a>Full list of attributes and methods:</h3>
<p>Here is a full list describing the attributes of the <code>R6</code> class created by <code>makeEnvironment</code>.</p>
<p><strong>Attributes</strong>:</p>
<ul>
<li><p><code>state</code> [any]: The current state observation of the environment. Depending on the problem this can be anything, e.g. a scalar integer, a matrix or a list.</p></li>
<li><p><code>reward</code> [integer(1)]: The current reward of the environment. It is always a scalar numeric value.</p></li>
<li><p><code>done</code> [logical(1)]: A logical flag specifying whether an episode is finished.</p></li>
<li><p><code>discount</code> [numeric(1) in [0, 1]]: The discount factor.</p></li>
<li><p><code>n.step</code> [integer(1)]: Number of steps, i.e. number of times <code>$step()</code> has been called.</p></li>
<li><p><code>episode.step</code> [integer(1)]: Number of steps in the current episode. In comparison to <code>n.step</code> it will be reset to 0 when <code>reset</code> is called. Each time <code>step</code> is called it is increased by 1.</p></li>
<li><p><code>episode.return</code> [numeric(1)]: The return in the current episode. Each time <code>step</code> is called the discounted <code>reward</code> is added. Will be reset to 0 when <code>reset</code> is called.</p></li>
<li><p><code>previous.state</code> [any]: The previous state of the environment. This is often the state which is updated in a reinforcement learning algorithm.</p></li>
</ul>
<p><strong>Methods</strong>:</p>
<ul>
<li><p><code>reset()</code>: Resets the environment, i.e. it sets the <code>state</code> attribute to a starting state and sets the <code>done</code> flag to <code>FALSE</code>. It is usually called at the beginning of an episode.</p></li>
<li><p><code>step(action)</code>: The interaction function between agent and environment. <code>step</code> is called with an action as an argument. It then takes the action and internally computes the following state, reward and whether an episode is finished and returns a list with <code>state</code>, <code>reward</code> and <code>done</code>.</p></li>
<li><p><code>visualize()</code>: Visualize the current state of the environment.</p></li>
</ul>
<hr>
</div>
<div id="references" class="section level3 unnumbered">
<h3 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h3>
<div id="refs" class="references">
<div id="ref-gym_openai">
<p>Brockman, Greg, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. “OpenAI Gym.” <em>CoRR</em> abs/1606.01540. <a href="http://arxiv.org/abs/1606.01540" class="uri">http://arxiv.org/abs/1606.01540</a>.</p>
</div>
<div id="ref-sutton2017">
<p>Sutton, Richard S., and Andrew G. Barto. 2017. “Reinforcement Learning : An Introduction.” Cambridge, MA, USA: <a href="http://incompleteideas.net/sutton/book/the-book-2nd.html" class="uri">http://incompleteideas.net/sutton/book/the-book-2nd.html</a>; MIT Press.</p>
</div>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#creation">Creation</a></li>
      <li><a href="#interaction">Interaction</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
