<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to reinforcelearn • reinforcelearn</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/algorithms.html">How to solve an environment?</a>
    </li>
    <li>
      <a href="../articles/environments.html">How to create an environment?</a>
    </li>
    <li>
      <a href="../articles/introduction.html">Introduction to reinforcelearn</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/markdumke/reinforcelearn">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Introduction to reinforcelearn</h1>
            
          </div>

    
    
<div class="contents">
<style type="text/css">
h1.title {
  font-size: 34px;
}
</style>
<p>This vignette gives a short introduction how to solve reinforcement learning problems with the <code>reinforcelearn</code> package.</p>
<hr>
<div id="set-up-an-environment" class="section level3">
<h3 class="hasAnchor">
<a href="#set-up-an-environment" class="anchor"></a>Set up an environment</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reinforcelearn)</code></pre></div>
<p>First we need to specify the problem, i.e. set up a reinforcement learning environment. Many problems can be formulated as a Markov Decision Process (MDP). To create an environment you need to specify the transition array and reward matrix of the MDP as arguments of the <code>makeEnvironment</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">P =<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))
P[, , <span class="dv">1</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
P[, , <span class="dv">2</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
R =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)  
env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="dt">transitions =</span> P, <span class="dt">rewards =</span> R)</code></pre></div>
<p>The function <code>makeEnvironment</code> returns an R6 class with a set of attributes and methods. There are attributes describing the properties of the state and action space and methods to interact with the environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">paste</span>(<span class="st">"State space:"</span> , env<span class="op">$</span>state.space)
<span class="co">#&gt; [1] "State space: Discrete"</span>
<span class="kw">paste</span>(<span class="st">"Number of actions:"</span>, env<span class="op">$</span>n.actions)
<span class="co">#&gt; [1] "Number of actions: 2"</span>

<span class="co"># Reset the environment</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="kw">print</span>(env)
<span class="co">#&gt; Number of steps: 0 </span>
<span class="co">#&gt; State: 0 </span>
<span class="co">#&gt; Reward:  </span>
<span class="co">#&gt; Done: FALSE</span>

env<span class="op">$</span><span class="kw">step</span>(<span class="dv">1</span>)
<span class="kw">print</span>(env)
<span class="co">#&gt; Number of steps: 1 </span>
<span class="co">#&gt; State: 1 </span>
<span class="co">#&gt; Reward: 10 </span>
<span class="co">#&gt; Done: TRUE</span></code></pre></div>
<p>For more details on the creation of environments have a look at the vignette <a href="environments.html">How to create an environment?</a>.</p>
<hr>
</div>
<div id="solve-an-environment" class="section level3">
<h3 class="hasAnchor">
<a href="#solve-an-environment" class="anchor"></a>Solve an environment</h3>
<p>Once you have created an environment you can find the optimal way to behave in this environment with one of the implemented algorithms, e.g. Value Iteration, Sarsa or Q-Learning. Here we will solve a simple gridworld MDP using Q-Learning.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Solve the windy gridworld task using Q-Learning</span>
env =<span class="st"> </span><span class="kw"><a href="../reference/windyGridworld.html">windyGridworld</a></span>()
res =<span class="st"> </span><span class="kw"><a href="../reference/qSigma.html">qlearning</a></span>(env)
res<span class="op">$</span>steps
<span class="co">#&gt;   [1] 1776  968  609  258  720  196  252  232  282  130   46  210  209  291</span>
<span class="co">#&gt;  [15]  127  148   58   42  258  267   77  107  138   27  113  151   45  192</span>
<span class="co">#&gt;  [29]  223  103   50   86   95   64   73  158   46  213   29  135  116   69</span>
<span class="co">#&gt;  [43]  107   36  125   82   35   78  132   23  190   26   26   49   45  122</span>
<span class="co">#&gt;  [57]   75  129   74   47   48   67   30   71  146   34   32  166   74   78</span>
<span class="co">#&gt;  [71]   48   27   25   62  143   32   25  142   32   34   36   66   32   64</span>
<span class="co">#&gt;  [85]   73  157   21   42   27   77   31  124   27  128   66   58   49   25</span>
<span class="co">#&gt;  [99]  104   57</span></code></pre></div>
<p>The algorithms return the state or action value function, sometimes also the policy and some statistics about learning behaviour, e.g. the number of steps per episode.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show value of each state.</span>
<span class="kw">print</span>(<span class="kw">matrix</span>(<span class="kw">round</span>(<span class="kw">apply</span>(res<span class="op">$</span>Q1, <span class="dv">1</span>, max), <span class="dv">1</span>), <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,] -7.2 -7.5 -7.9 -8.6 -9.2 -9.5 -8.8 -7.9 -6.9  -6.0</span>
<span class="co">#&gt; [2,] -7.0 -7.1 -7.2 -7.6 -7.8 -7.4 -6.2 -5.1 -5.2  -5.0</span>
<span class="co">#&gt; [3,] -6.7 -6.7 -6.6 -6.8 -6.5 -5.4 -4.5 -2.9 -4.1  -4.0</span>
<span class="co">#&gt; [4,] -6.6 -6.2 -5.9 -5.9 -5.1 -3.8 -2.5  0.0 -2.8  -3.0</span>
<span class="co">#&gt; [5,] -5.9 -5.6 -5.3 -5.1 -3.8 -2.3  0.0 -0.5 -1.0  -2.0</span>
<span class="co">#&gt; [6,] -5.3 -5.0 -4.7 -4.2 -2.8  0.0  0.0 -0.1 -0.8  -1.3</span>
<span class="co">#&gt; [7,] -5.0 -4.6 -4.1 -3.3  0.0  0.0  0.0  0.0 -0.3  -0.8</span></code></pre></div>
<p>We can then get the optimal policy by taking the argmax over the action value function Q.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">optimal.policy =<span class="st"> </span><span class="kw">max.col</span>(res<span class="op">$</span>Q1) <span class="op">-</span><span class="st"> </span>1L
<span class="kw">print</span>(<span class="kw">matrix</span>(optimal.policy, <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,]    3    0    3    0    0    0    1    1    1     3</span>
<span class="co">#&gt; [2,]    2    0    3    2    3    1    1    2    3     3</span>
<span class="co">#&gt; [3,]    0    0    2    0    3    3    2    0    3     3</span>
<span class="co">#&gt; [4,]    3    3    3    1    3    1    1    3    3     3</span>
<span class="co">#&gt; [5,]    1    0    1    1    1    3    1    3    0     0</span>
<span class="co">#&gt; [6,]    2    0    3    2    1    1    0    0    3     0</span>
<span class="co">#&gt; [7,]    0    1    2    1    0    1    1    1    1     3</span></code></pre></div>
<p>To learn more about algorithms implemented in <code>reinforcelearn</code> have a look at the <a href="algorithms.html">How to solve an environment?</a> vignette.</p>
<hr>
<p>Also have a look at the other vignettes:</p>
<ul>
<li><p><a href="environments.html">How to create an environment?</a></p></li>
<li><p><a href="algorithms.html">How to solve an environment?</a>.</p></li>
</ul>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
