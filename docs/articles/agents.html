<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Agents • reinforcelearn</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/agents.html">Agents</a>
    </li>
    <li>
      <a href="../articles/environments.html">Environments</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Agents</h1>
                        <h4 class="author">Markus Dumke</h4>
            
            <h4 class="date">2017-12-21</h4>
          </div>

    
    
<div class="contents">
<style type="text/css">
  h1.title {
  font-size: 34px;
  }
</style>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12</span>)
<span class="kw">library</span>(reinforcelearn)</code></pre></div>
<p>A reinforcement learning agent usually consists of three parts: a policy, a value function representation and an algorithm which updates the value function or policy parameters. In the following it will be explained how to create an agent in <code>reinforcelearn</code> to solve an environment.</p>
<p>You can create an agent with the function <code>makeAgent</code>. This will create an R6 class object with the corresponding policy, value function and algorithm.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">goal.states =</span> 0L)
agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(<span class="dt">policy =</span> <span class="st">"softmax"</span>, <span class="dt">val.fun =</span> <span class="st">"table"</span>, <span class="dt">algorithm =</span> <span class="st">"qlearning"</span>)</code></pre></div>
<p>Then you can run the agent in the environment by calling <code>interact</code> for a specified number of steps or episodes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.episodes =</span> 5L)
<span class="co">#&gt; Episode 1 finished after 1 steps with a return of -1</span>
<span class="co">#&gt; Episode 2 finished after 25 steps with a return of -25</span>
<span class="co">#&gt; Episode 3 finished after 3 steps with a return of -3</span>
<span class="co">#&gt; Episode 4 finished after 15 steps with a return of -15</span>
<span class="co">#&gt; Episode 5 finished after 5 steps with a return of -5</span>
<span class="co">#&gt; $returns</span>
<span class="co">#&gt; [1]  -1 -25  -3 -15  -5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $steps</span>
<span class="co">#&gt; [1]  1 25  3 15  5</span></code></pre></div>
<p>Note that <code>interact</code> returns a list with the number of steps and returns per episode. Furthermore it will change the environment and agent object. So the environment’s state or the agent’s value function weights will have most likely changed after the interaction.</p>
<p>Although you can directly access the agent object, this is not recommended as this will be very likely to change in the next package versions. Instead use one of the accessor functions to e.g. get the weights of the action value function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/getValueFunction.html">getValueFunction</a></span>(agent)
<span class="co">#&gt;           [,1]    [,2]    [,3]    [,4]</span>
<span class="co">#&gt;  [1,]  0.00000  0.0000  0.0000  0.0000</span>
<span class="co">#&gt;  [2,] -0.40951 -0.3081 -0.3439  0.0000</span>
<span class="co">#&gt;  [3,] -0.40951 -0.3900 -0.3710 -0.2000</span>
<span class="co">#&gt;  [4,]  0.00000 -0.1000  0.0000  0.0000</span>
<span class="co">#&gt;  [5,]  0.00000 -0.2900 -0.1900  0.0000</span>
<span class="co">#&gt;  [6,] -0.27100 -0.1000 -0.2900 -0.1900</span>
<span class="co">#&gt;  [7,]  0.00000  0.0000  0.0000  0.0000</span>
<span class="co">#&gt;  [8,]  0.00000  0.0000  0.0000  0.0000</span>
<span class="co">#&gt;  [9,]  0.00000 -0.1000 -0.2000 -0.3439</span></code></pre></div>
<div id="policies" class="section level2">
<h2 class="hasAnchor">
<a href="#policies" class="anchor"></a>Policies</h2>
<p>A policy is the agent’s behavior function. We can define the policy with <code>makePolicy</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Uniform random policy</span>
<span class="kw"><a href="../reference/makePolicy.html">makePolicy</a></span>(<span class="st">"random"</span>)
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "random"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args</span>
<span class="co">#&gt; list()</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "Policy"</span>

<span class="co"># Epsilon-greedy policy</span>
<span class="kw"><a href="../reference/makePolicy.html">makePolicy</a></span>(<span class="st">"epsilon.greedy"</span>, <span class="dt">epsilon =</span> <span class="fl">0.2</span>)
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "epsilon.greedy"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args</span>
<span class="co">#&gt; $args$epsilon</span>
<span class="co">#&gt; [1] 0.2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "Policy"</span>

<span class="co"># Softmax policy</span>
<span class="kw"><a href="../reference/makePolicy.html">makePolicy</a></span>(<span class="st">"softmax"</span>)
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "softmax"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args</span>
<span class="co">#&gt; list()</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "Policy"</span></code></pre></div>
<p>This will just capture what policy to use and the policy will then be created when we create the agent.</p>
</div>
<div id="value-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#value-functions" class="anchor"></a>Value Functions</h2>
<p>Many reinforcement learning algorithms use a value function to learn values of state and action pairs. The value function can be represented with different types of function approximation, e.g. as a table or neural network.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/makeValueFunction.html">makeValueFunction</a></span>(<span class="st">"table"</span>, <span class="dt">n.states =</span> 9L, <span class="dt">n.actions =</span> 4L)
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "table"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args</span>
<span class="co">#&gt; $args$n.states</span>
<span class="co">#&gt; [1] 9</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args$n.actions</span>
<span class="co">#&gt; [1] 4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "ValueFunction"</span></code></pre></div>
<p>For a neural network you can use the <code>keras</code> package. Therefore you need to specify a the model’s architecture and pass these on to <code>makeValueFunction</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)
model =<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">shape =</span> 10L, <span class="dt">input_shape =</span> 4L, <span class="dt">activation =</span> <span class="st">"linear"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="kw">optimizer_sgd</span>(<span class="dt">lr =</span> <span class="fl">0.1</span>), <span class="dt">loss =</span> <span class="st">"mae"</span>)
<span class="kw"><a href="../reference/makeValueFunction.html">makeValueFunction</a></span>(<span class="st">"neural.network"</span>, model)</code></pre></div>
<p>Note that online neural network training is currently very slow. One way to work with this is to make updates to the value function not after every interaction, but to store all interactions in a replay memory and make updates to the neural network only once in a while. Read more about this in Section Experience Replay.</p>
<p>Often you need to preprocess the state observation in a way the agent can work with this. Therefore you can pass on a function to the <code>preprocess</code> argument of <code>makeAgent</code>, which will then be applied to the state observation before the agent learns on this.</p>
<p>For neural network training the outcome of <code>preprocess</code> must be a one-row matrix in order to be able to learn.</p>
</div>
<div id="algorithms" class="section level2">
<h2 class="hasAnchor">
<a href="#algorithms" class="anchor"></a>Algorithms</h2>
<p>The algorithm defines how to learn from an interaction with the environment. We can set up an algorithm using the function <code>makeAlgorithm</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/makeAlgorithm.html">makeAlgorithm</a></span>(<span class="st">"qlearning"</span>)
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "qlearning"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $args</span>
<span class="co">#&gt; list()</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "Algorithm"</span></code></pre></div>
</div>
<div id="agent" class="section level2">
<h2 class="hasAnchor">
<a href="#agent" class="anchor"></a>Agent</h2>
<p>If we have defined policy, value function and algorithm we can create the agent by calling <code>makeAgent</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">policy =<span class="st"> </span><span class="kw"><a href="../reference/makePolicy.html">makePolicy</a></span>(<span class="st">"epsilon.greedy"</span>, <span class="dt">epsilon =</span> <span class="fl">0.2</span>)
val.fun =<span class="st"> </span><span class="kw"><a href="../reference/makeValueFunction.html">makeValueFunction</a></span>(<span class="st">"table"</span>, <span class="dt">n.states =</span> 9L, <span class="dt">n.actions =</span> 4L)
algorithm =<span class="st"> </span><span class="kw"><a href="../reference/makeAlgorithm.html">makeAlgorithm</a></span>(<span class="st">"qlearning"</span>)

agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(policy, val.fun, algorithm)</code></pre></div>
<p>Note that you can also call <code>makeAgent</code> with character arguments which can save some typing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(<span class="st">"epsilon.greedy"</span>, <span class="st">"table"</span>, <span class="st">"qlearning"</span>, <span class="dt">epsilon =</span> <span class="fl">0.2</span>)</code></pre></div>
</div>
<div id="interaction" class="section level2">
<h2 class="hasAnchor">
<a href="#interaction" class="anchor"></a>Interaction</h2>
<p>You can run an interaction between an agent and environment with the <code>interact</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>), <span class="dt">goal.states =</span> 0L)
agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(<span class="st">"random"</span>)

<span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.steps =</span> 3L, <span class="dt">visualize =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt;  - - </span>
<span class="co">#&gt;  o - </span>
<span class="co">#&gt;  - -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  - - </span>
<span class="co">#&gt;  o - </span>
<span class="co">#&gt;  - -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  - - </span>
<span class="co">#&gt;  - o </span>
<span class="co">#&gt;  - -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $returns</span>
<span class="co">#&gt; numeric(0)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $steps</span>
<span class="co">#&gt; integer(0)</span></code></pre></div>
<p>It allows you to run an interaction for a specified number of steps or episodes and you can also specify a maximum number of steps per episode. This makes it very flexible to step through the environment one action after the other. Note you can also run an interaction without learning.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>), <span class="dt">goal.states =</span> 0L, 
  <span class="dt">initial.state =</span> 15L)
agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(<span class="st">"random"</span>)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>3L) {
  ## comment in the next line to wait on enter press before taking the next action.
  <span class="co"># invisible(readline(prompt = "Press [enter] to take the next action"))</span>
  <span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.steps =</span> 1L, <span class="dt">learn =</span> <span class="ot">FALSE</span>, <span class="dt">visualize =</span> <span class="ot">TRUE</span>)
}
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - o</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - o -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - o - </span>
<span class="co">#&gt;  - - - -</span>
<span class="co">#&gt; </span></code></pre></div>
<div id="experience-replay" class="section level3">
<h3 class="hasAnchor">
<a href="#experience-replay" class="anchor"></a>Experience replay</h3>
<p>Experience replay is a technique to learn at once from multiple past observations. Therefore all the states, actions, rewards and subsequent states will be stored in a list (the so called replay memory) and at each step a random batch from this memory will be replayed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">memory =</span> <span class="kw"><a href="../reference/makeReplayMemory.html">makeReplayMemory</a></span>(<span class="dt">size =</span> 2L, <span class="dt">batch.size =</span> 1L))
<span class="co">#&gt; $size</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $batch.size</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "ReplayMemory"</span>

agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(<span class="st">"random"</span>, <span class="dt">experience.replay =</span> memory)

<span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.steps =</span> 2L, <span class="dt">visualize =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - o - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - - - </span>
<span class="co">#&gt;  - - o - </span>
<span class="co">#&gt;  - - - -</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $returns</span>
<span class="co">#&gt; numeric(0)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $steps</span>
<span class="co">#&gt; integer(0)</span>

<span class="kw"><a href="../reference/getReplayMemory.html">getReplayMemory</a></span>(agent)
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; [[1]]$state</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[1]]$action</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[1]]$reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[1]]$next.state</span>
<span class="co">#&gt; [1] 6</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; [[2]]$state</span>
<span class="co">#&gt; [1] 6</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]$action</span>
<span class="co">#&gt; [1] 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]$reward</span>
<span class="co">#&gt; [1] -1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]$next.state</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
<p>Here is an example training with experience replay, where the value function is updated only every 21 steps.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span><span class="kw"><a href="../reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"gridworld"</span>, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>), <span class="dt">goal.states =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">15</span>))

policy =<span class="st"> </span><span class="kw"><a href="../reference/makePolicy.html">makePolicy</a></span>(<span class="st">"epsilon.greedy"</span>, <span class="dt">epsilon =</span> <span class="fl">0.1</span>)
memory =<span class="st"> </span><span class="kw"><a href="../reference/makeReplayMemory.html">makeReplayMemory</a></span>(<span class="dt">size =</span> 100L, <span class="dt">batch.size =</span> 20L)

agent =<span class="st"> </span><span class="kw"><a href="../reference/makeAgent.html">makeAgent</a></span>(policy, <span class="st">"table"</span>, <span class="st">"qlearning"</span>, <span class="dt">experience.replay =</span> memory)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) {
  <span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.steps =</span> 20L, <span class="dt">learn =</span> <span class="ot">FALSE</span>)
  <span class="kw"><a href="../reference/interact.html">interact</a></span>(env, agent, <span class="dt">n.steps =</span> 1L, <span class="dt">learn =</span> <span class="ot">TRUE</span>)
}
action.vals =<span class="st"> </span><span class="kw"><a href="../reference/getValueFunction.html">getValueFunction</a></span>(agent)
<span class="kw">matrix</span>(<span class="kw"><a href="../reference/getStateValues.html">getStateValues</a></span>(action.vals), <span class="dt">ncol =</span> 4L)
<span class="co">#&gt;            [,1]      [,2]      [,3]      [,4]</span>
<span class="co">#&gt; [1,]   0.000000 -3.012074 -4.966259 -7.397651</span>
<span class="co">#&gt; [2,]  -2.545300 -5.650029 -7.306089 -4.991932</span>
<span class="co">#&gt; [3,]  -6.271404 -6.434747 -6.101606 -3.336008</span>
<span class="co">#&gt; [4,] -12.746046 -7.714610 -3.327779  0.000000</span></code></pre></div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#policies">Policies</a></li>
      <li><a href="#value-functions">Value Functions</a></li>
      <li><a href="#algorithms">Algorithms</a></li>
      <li><a href="#agent">Agent</a></li>
      <li><a href="#interaction">Interaction</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
