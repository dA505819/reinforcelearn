<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Reinforcement Learning in R â€¢ reinforcelearn</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="/index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/algorithms.html">How to solve an environment?</a>
    </li>
    <li>
      <a href="articles/environments.html">How to create an environment?</a>
    </li>
    <li>
      <a href="articles/introduction.html">Introduction to reinforcelearn</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/markdumke/reinforcelearn">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    

    
    
<div class="contents">
<div id="reinforcement-learning-in-r" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#reinforcement-learning-in-r" class="anchor"></a>Reinforcement Learning in R <img src="reinforcelearn.png" align="right" height="36">
</h1></div>

<div id="documentation" class="section level3">
<h3 class="hasAnchor">
<a href="#documentation" class="anchor"></a>Documentation</h3>
<p><a href="https://markdumke.github.io/reinforcelearn">Website</a></p>
<hr>
</div>
<div id="installation" class="section level3">
<h3 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages("devtools")</span>
devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"markdumke/reinforcelearn"</span>)</code></pre></div>
<hr>
</div>
<div id="get-started" class="section level3">
<h3 class="hasAnchor">
<a href="#get-started" class="anchor"></a>Get started</h3>
<p>Reinforcement Learning with the package <code>reinforcelearn</code> is as easy as</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reinforcelearn)

<span class="co"># Create gridworld environment</span>
env =<span class="st"> </span><span class="kw"><a href="reference/windyGridworld.html">windyGridworld</a></span>()

<span class="co"># Solve environment using Sarsa</span>
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">sarsa</a></span>(env, <span class="dt">n.episodes =</span> <span class="dv">30</span>)
<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1]  808 1839  742  423  129  219  512  246   54  169  110  419   42  287</span>
<span class="co">#&gt; [15]  145  149  136   71  132  224   70  198  174   52  115  160  151  143</span>
<span class="co">#&gt; [29]  105  144</span></code></pre></div>
<hr>
</div>
<div id="environments" class="section level3">
<h3 class="hasAnchor">
<a href="#environments" class="anchor"></a>Environments</h3>
<p>With <code>makeEnvironment</code> you can create a reinforcement learning environment from a Markov Decision Process.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create environment from MDP.</span>
P =<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
P[, , <span class="dv">1</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
P[, , <span class="dv">2</span>] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
R =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)  
env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="dt">transitions =</span> P, <span class="dt">rewards =</span> R)</code></pre></div>
<p>The environment is an <code>R6</code> class with a set of attributes and methods. You can interact with the environment via the <code>reset</code> and <code>step</code> method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Reset environment.</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="kw">print</span>(env)
<span class="co">#&gt; Number of steps: 0 </span>
<span class="co">#&gt; State: 0 </span>
<span class="co">#&gt; Reward:  </span>
<span class="co">#&gt; Done: FALSE</span>

<span class="co"># Take action 0.</span>
env<span class="op">$</span><span class="kw">step</span>(<span class="dv">0</span>)
<span class="kw">print</span>(env)
<span class="co">#&gt; Number of steps: 1 </span>
<span class="co">#&gt; State: 1 </span>
<span class="co">#&gt; Reward: 5 </span>
<span class="co">#&gt; Done: TRUE</span></code></pre></div>
<p>You can also create an environment from <a href="https://gym.openai.com/">OpenAI Gym</a> via the <code>gym</code> package. You need to install all dependencies listed <a href="https://github.com/openai/gym-http-api">here</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create an OpenAI Gym environment.</span>
<span class="co"># Make sure you have Python and Gym installed.</span>
<span class="co"># Start server.</span>
package.path =<span class="st"> </span><span class="kw">system.file</span>(<span class="dt">package =</span> <span class="st">"reinforcelearn"</span>)
path2pythonfile =<span class="st"> </span><span class="kw">paste0</span>(package.path, <span class="st">"/gym_http_server.py"</span>)
<span class="kw">system2</span>(<span class="st">"python"</span>, <span class="dt">args =</span> path2pythonfile, <span class="dt">stdout =</span> <span class="ot">NULL</span>,
  <span class="dt">wait =</span> <span class="ot">FALSE</span>, <span class="dt">invisible =</span> <span class="ot">FALSE</span>)

env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"MountainCar-v0"</span>)

<span class="co"># Take random actions for 200 steps.</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">200</span>) {
  action =<span class="st"> </span><span class="kw">sample</span>(env<span class="op">$</span>actions, <span class="dv">1</span>)
  env<span class="op">$</span><span class="kw">step</span>(action)
}
env<span class="op">$</span><span class="kw">close</span>()</code></pre></div>
<p>This should open a Python window showing the interaction with the environment.</p>
<p>For more details on how to create an environment have a look at the vignette: <a href="https://markdumke.github.io/reinforcelearn/articles/environments.html">How to create an environment?</a></p>
<hr>
</div>
<div id="algorithms" class="section level3">
<h3 class="hasAnchor">
<a href="#algorithms" class="anchor"></a>Algorithms</h3>
<p>After you created an environment you can use various reinforcement learning algorithms to solve this environment. For example, for a tabular environment like gridworld you can use tabular Q-Learning to solve it and find the optimal action value function <span class="math inline">\(Q*\)</span>. You can set various parameters like the learning rate, the number of episodes, the discount factor or epsilon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create the windy gridworld environment.</span>
env =<span class="st"> </span><span class="kw"><a href="reference/windyGridworld.html">windyGridworld</a></span>()
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">qlearning</a></span>(env, <span class="dt">n.episodes =</span> <span class="dv">30</span>)
<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1]  791 1915  793   84  492   99  196  607  144  461   76  129  318  112</span>
<span class="co">#&gt; [15]   75   66  327  220   44   42  116   38   82  159   89  280   81  166</span>
<span class="co">#&gt; [29]   42  190</span>

<span class="co"># Show value of each state.</span>
<span class="kw">print</span>(<span class="kw">matrix</span>(<span class="kw">round</span>(<span class="kw">apply</span>(res<span class="op">$</span>Q1, <span class="dv">1</span>, max), <span class="dv">1</span>), <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,] -4.8 -5.0 -5.5 -6.3 -7.0 -7.4 -7.3 -6.8 -6.0  -5.2</span>
<span class="co">#&gt; [2,] -4.6 -4.7 -4.8 -5.2 -4.8 -4.2 -2.9 -3.9 -4.4  -4.3</span>
<span class="co">#&gt; [3,] -4.3 -4.2 -4.1 -4.2 -3.3 -1.9 -1.4 -2.4 -3.3  -3.5</span>
<span class="co">#&gt; [4,] -4.0 -3.8 -3.4 -3.2 -2.0 -1.0 -0.2  0.0 -2.2  -2.6</span>
<span class="co">#&gt; [5,] -3.4 -3.2 -2.8 -2.3 -1.3 -0.4  0.0 -0.3 -0.9  -1.8</span>
<span class="co">#&gt; [6,] -3.0 -2.7 -2.3 -1.7 -0.6  0.0  0.0  0.0 -0.7  -1.1</span>
<span class="co">#&gt; [7,] -2.7 -2.3 -1.8 -1.1  0.0  0.0  0.0  0.0 -0.3  -0.7</span></code></pre></div>
<p>We can then get the policy by taking the argmax over the action value function Q.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">policy =<span class="st"> </span><span class="kw">max.col</span>(res<span class="op">$</span>Q1) <span class="op">-</span><span class="st"> </span>1L
<span class="kw">print</span>(<span class="kw">matrix</span>(policy, <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,]    2    1    3    0    0    1    3    1    3     3</span>
<span class="co">#&gt; [2,]    2    2    3    0    3    3    0    3    1     3</span>
<span class="co">#&gt; [3,]    0    3    3    2    0    1    3    0    0     0</span>
<span class="co">#&gt; [4,]    3    0    1    1    1    3    3    3    0     3</span>
<span class="co">#&gt; [5,]    3    0    1    3    0    1    0    3    1     3</span>
<span class="co">#&gt; [6,]    0    3    3    2    3    3    1    3    0     1</span>
<span class="co">#&gt; [7,]    1    1    1    2    1    1    2    2    0     1</span></code></pre></div>
<p>For more details on algorithms have a look at the vignette: <a href="https://markdumke.github.io/reinforcelearn/articles/algorithms.html">How to solve an environment?</a></p>
<hr>
</div>
<div id="value-function-approximation" class="section level3">
<h3 class="hasAnchor">
<a href="#value-function-approximation" class="anchor"></a>Value function approximation</h3>
<p>When the state space is large or even continuous tabular solution methods cannot be applied. Then it is better to approximate the value function using a function approximator. We need to define a function, which preprocesses the state observation, so that the function approximator can work with it. Here is an example solving the mountain car problem using linear function approximation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up the Mountain Car problem</span>
m =<span class="st"> </span><span class="kw"><a href="reference/mountainCar.html">mountainCar</a></span>()

<span class="co"># Define preprocessing function (here grid tiling)</span>
n.tilings =<span class="st"> </span><span class="dv">8</span>
max.size =<span class="st"> </span><span class="dv">4096</span>
iht =<span class="st"> </span><span class="kw"><a href="reference/tilecoding.html">IHT</a></span>(max.size)

position.max =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">1</span>]][<span class="dv">2</span>]
position.min =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">1</span>]][<span class="dv">1</span>]
velocity.max =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">2</span>]][<span class="dv">2</span>]
velocity.min =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">2</span>]][<span class="dv">1</span>]
position.scale =<span class="st"> </span>n.tilings <span class="op">/</span><span class="st"> </span>(position.max <span class="op">-</span><span class="st"> </span>position.min)
velocity.scale =<span class="st"> </span>n.tilings <span class="op">/</span><span class="st"> </span>(velocity.max <span class="op">-</span><span class="st"> </span>velocity.min)

preprocessState =<span class="st"> </span><span class="cf">function</span>(state) {
  <span class="co"># scale state observation</span>
  state =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(position.scale <span class="op">*</span><span class="st"> </span>state[<span class="dv">1</span>], velocity.scale <span class="op">*</span><span class="st"> </span>state[<span class="dv">2</span>]), <span class="dt">ncol =</span> <span class="dv">2</span>)
  <span class="co"># get active tiles</span>
  active.tiles =<span class="st"> </span><span class="kw"><a href="reference/tilecoding.html">tiles</a></span>(iht, <span class="dv">8</span>, state)
  <span class="co"># return n hot vector with 1 at the position of each active tile</span>
  <span class="kw"><a href="reference/makeNHot.html">makeNHot</a></span>(active.tiles, max.size)
}

<span class="kw">set.seed</span>(<span class="dv">123</span>)
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">qlearning</a></span>(m, <span class="dt">fun.approx =</span> <span class="st">"linear"</span>, 
  <span class="dt">preprocessState =</span> preprocessState, <span class="dt">n.episodes =</span> <span class="dv">20</span>)
<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1] 1211  903  536  420  406  241  241  239  233  232  204  241  194  235</span>
<span class="co">#&gt; [15]  233  167  198  165  234  162</span></code></pre></div>
<hr>
</div>
<div id="vignettes" class="section level3">
<h3 class="hasAnchor">
<a href="#vignettes" class="anchor"></a>Vignettes</h3>
<p>Also have a look at the vignettes for further examples.</p>
<ul>
<li><a href="https://markdumke.github.io/reinforcelearn/articles/introduction.html">Introduction to reinforcelearn</a></li>
<li><a href="https://markdumke.github.io/reinforcelearn/articles/environments.html">How to create an environment?</a></li>
<li><a href="https://markdumke.github.io/reinforcelearn/articles/algorithms.html">How to solve an environment?</a></li>
</ul>
<hr>
<p>Logo is a modification of <a href="https://www.r-project.org/logo/" class="uri">https://www.r-project.org/logo/</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2 class="hasAnchor">
<a href="#sidebar" class="anchor"></a>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/markdumke/reinforcelearn">https://â€‹github.com/â€‹markdumke/â€‹reinforcelearn</a>
</li>
<li>Report a bug at <br><a href="https://github.com/markdumke/reinforcelearn/issues">https://â€‹github.com/â€‹markdumke/â€‹reinforcelearn/â€‹issues</a>
</li>
</ul>
<h2>License</h2>
<p><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file <a href="LICENSE.html">LICENSE</a></p>
<h2>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html">Citing reinforcelearn</a></li>
</ul>
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Markus Dumke <br><small class="roles"> Author, maintainer </small> </li>
</ul>
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://travis-ci.org/markdumke/reinforcelearn"><img src="https://travis-ci.org/markdumke/reinforcelearn.svg?branch=master" alt="Travis-CI Build Status"></a></li>
<li><a href="https://cran.r-project.org/package=reinforcelearn"><img src="http://www.r-pkg.org/badges/version/reinforcelearn" alt="CRAN_Status_Badge"></a></li>
<li><a href="https://codecov.io/github/markdumke/reinforcelearn?branch=master"><img src="https://img.shields.io/codecov/c/github/markdumke/reinforcelearn/master.svg?maxAge=600" alt="Coverage Status"></a></li>
</ul>
</div>

</div>


      <footer><div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
