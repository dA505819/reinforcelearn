<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Reinforcement Learning â€¢ reinforcelearn</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">reinforcelearn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/algorithms.html">How to solve an environment?</a>
    </li>
    <li>
      <a href="articles/environments.html">How to create an environment?</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    

    
    
<div class="contents">
<div id="reinforcement-learning-in-r" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#reinforcement-learning-in-r" class="anchor"></a>Reinforcement Learning in R <img src="reinforcelearn.png" align="right" height="36">
</h1></div>

<div id="documentation" class="section level3">
<h3 class="hasAnchor">
<a href="#documentation" class="anchor"></a>Documentation</h3>
<p><a href="https://markdumke.github.io/reinforcelearn">Website</a></p>
<hr>
</div>
<div id="installation" class="section level3">
<h3 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install from CRAN</span>
<span class="kw">install.packages</span>(<span class="st">"reinforcelearn"</span>)

<span class="co"># install development version from github</span>
devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"markdumke/reinforcelearn"</span>)</code></pre></div>
<hr>
</div>
<div id="get-started" class="section level3">
<h3 class="hasAnchor">
<a href="#get-started" class="anchor"></a>Get started</h3>
<p>Reinforcement Learning with the package <code>reinforcelearn</code> is as easy as</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reinforcelearn)

<span class="co"># Create gridworld environment</span>
env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"WindyGridworld"</span>)

<span class="co"># Solve environment using Sarsa</span>
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">sarsa</a></span>(env, <span class="dt">n.episodes =</span> <span class="dv">30</span>)
<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1]  827 2563 3381 3664 4141 4530 4612 4892 5115 5338 5429 5641 5892 6054</span>
<span class="co">#&gt; [15] 6101 6315 6484 6627 6706 6866 7033 7173 7296 7399 7453 7581 7806 7885</span>
<span class="co">#&gt; [29] 8055 8116</span></code></pre></div>
<hr>
</div>
<div id="environments" class="section level3">
<h3 class="hasAnchor">
<a href="#environments" class="anchor"></a>Environments</h3>
<p>With <code>makeEnvironment</code> you can create reinforcement learning environments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create environment.</span>
step =<span class="st"> </span><span class="cf">function</span>(self, action) {
  state =<span class="st"> </span><span class="kw">list</span>(<span class="dt">mean =</span> action <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>), <span class="dt">sd =</span> <span class="kw">runif</span>(<span class="dv">1</span>))
  reward =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, state[[<span class="dv">1</span>]], state[[<span class="dv">2</span>]])
  done =<span class="st"> </span><span class="ot">FALSE</span>
  <span class="kw">list</span>(state, reward, done)
}

reset =<span class="st"> </span><span class="cf">function</span>() {
  state =<span class="st"> </span><span class="kw">list</span>(<span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
  state
}

env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"custom"</span>, <span class="dt">step =</span> step, <span class="dt">reset =</span> reset)</code></pre></div>
<p>The environment is an <code>R6</code> class with a set of attributes and methods. You can interact with the environment via the <code>reset</code> and <code>step</code> method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Reset environment.</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="co">#&gt; $mean</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sd</span>
<span class="co">#&gt; [1] 1</span>
<span class="co"># Take action.</span>
env<span class="op">$</span><span class="kw">step</span>(<span class="dv">100</span>)
<span class="co">#&gt; $state</span>
<span class="co">#&gt; $state$mean</span>
<span class="co">#&gt; [1] 100.1641</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $state$sd</span>
<span class="co">#&gt; [1] 0.3432847</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $reward</span>
<span class="co">#&gt; [1] 99.93667</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $done</span>
<span class="co">#&gt; [1] FALSE</span></code></pre></div>
<p>There are some predefined environment classes, e.g. <code>MDPEnvironment</code>, which allows you to create a Markov Decision Process by passing on state transition array and reward matrix, or <code>GymEnvironment</code>, where you can use toy problems from <a href="https://gym.openai.com/">OpenAI Gym</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create an OpenAI Gym environment.</span>
<span class="co"># Make sure you have Python, gym and reticulate installed.</span>
env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"Gym"</span>, <span class="st">"MountainCar-v0"</span>)

<span class="co"># Take random actions for 200 steps.</span>
env<span class="op">$</span><span class="kw">reset</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">200</span>) {
  action =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">1</span>)
  env<span class="op">$</span><span class="kw">step</span>(action)
  env<span class="op">$</span><span class="kw">visualize</span>()
}
env<span class="op">$</span><span class="kw">close</span>()</code></pre></div>
<p>This should open a Python window showing the interaction with the environment.</p>
<p>For more details on how to create an environment have a look at the vignette: <a href="https://markdumke.github.io/reinforcelearn/articles/environments.html">How to create an environment?</a></p>
<hr>
</div>
<div id="algorithms" class="section level3">
<h3 class="hasAnchor">
<a href="#algorithms" class="anchor"></a>Algorithms</h3>
<p>After you created an environment you can use various reinforcement learning algorithms to solve this environment. For example, for a tabular environment like gridworld you can use tabular Q-Learning to solve it and find the optimal action value function <span class="math inline">\(Q*\)</span>. You can set various parameters like the learning rate, the number of episodes, the discount factor or epsilon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create the windy gridworld environment.</span>
env =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"WindyGridworld"</span>)
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">qlearning</a></span>(env, <span class="dt">n.episodes =</span> <span class="dv">30</span>)

<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1]  784 2716 3282 3636 4196 4334 4654 4935 5121 5359 5705 5898 6015 6139</span>
<span class="co">#&gt; [15] 6265 6316 6463 6697 6842 6958 7027 7176 7284 7336 7471 7556 7636 7874</span>
<span class="co">#&gt; [29] 7915 8007</span>

<span class="co"># Show value of each state.</span>
<span class="kw">print</span>(<span class="kw">matrix</span>(<span class="kw">round</span>(<span class="kw">apply</span>(res<span class="op">$</span>Q1, <span class="dv">1</span>, max), <span class="dv">1</span>), <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,] -4.6 -4.8 -5.4 -6.1 -6.8 -7.3 -7.2 -6.7 -6.0  -5.1</span>
<span class="co">#&gt; [2,] -4.5 -4.5 -4.7 -5.0 -4.8 -4.1 -2.8 -3.8 -4.3  -4.3</span>
<span class="co">#&gt; [3,] -4.1 -4.0 -4.0 -4.1 -3.2 -1.8 -1.2 -2.4 -3.1  -3.4</span>
<span class="co">#&gt; [4,] -3.9 -3.6 -3.3 -3.1 -1.8 -0.8 -0.2  0.0 -2.2  -2.6</span>
<span class="co">#&gt; [5,] -3.3 -3.1 -2.7 -2.2 -1.1 -0.3  0.0 -0.3 -0.9  -1.7</span>
<span class="co">#&gt; [6,] -2.9 -2.6 -2.2 -1.6 -0.6  0.0  0.0  0.0 -0.7  -1.1</span>
<span class="co">#&gt; [7,] -2.6 -2.3 -1.8 -1.1  0.0  0.0  0.0  0.0 -0.3  -0.7</span></code></pre></div>
<p>We can then get the policy by taking the argmax over the action value function Q.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">policy =<span class="st"> </span><span class="kw">max.col</span>(res<span class="op">$</span>Q1) <span class="op">-</span><span class="st"> </span>1L
<span class="kw">print</span>(<span class="kw">matrix</span>(policy, <span class="dt">ncol =</span> <span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span>
<span class="co">#&gt; [1,]    1    3    3    0    0    0    3    1    1     3</span>
<span class="co">#&gt; [2,]    2    3    0    3    0    2    0    0    1     3</span>
<span class="co">#&gt; [3,]    3    1    2    2    3    0    2    0    0     3</span>
<span class="co">#&gt; [4,]    3    3    3    1    3    3    0    3    3     3</span>
<span class="co">#&gt; [5,]    2    0    1    1    3    0    0    0    0     3</span>
<span class="co">#&gt; [6,]    2    1    0    3    3    2    2    3    1     3</span>
<span class="co">#&gt; [7,]    2    1    1    3    2    2    2    0    3     0</span></code></pre></div>
<p>For more details on algorithms have a look at the vignette: <a href="https://markdumke.github.io/reinforcelearn/articles/algorithms.html">How to solve an environment?</a></p>
<hr>
</div>
<div id="value-function-approximation" class="section level3">
<h3 class="hasAnchor">
<a href="#value-function-approximation" class="anchor"></a>Value function approximation</h3>
<p>When the state space is large or even continuous tabular solution methods cannot be applied. Then it is better to approximate the value function using a function approximator. We need to define a function, which preprocesses the state observation, so that the function approximator can work with it. Here is an example solving the mountain car problem using linear function approximation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up the Mountain Car problem.</span>
m =<span class="st"> </span><span class="kw"><a href="reference/makeEnvironment.html">makeEnvironment</a></span>(<span class="st">"MountainCar"</span>)

<span class="co"># Define preprocessing function (here grid tiling).</span>
n.tilings =<span class="st"> </span><span class="dv">8</span>
max.size =<span class="st"> </span><span class="dv">4096</span>
iht =<span class="st"> </span><span class="kw"><a href="reference/tilecoding.html">IHT</a></span>(max.size)

position.max =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">1</span>]][<span class="dv">2</span>]
position.min =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">1</span>]][<span class="dv">1</span>]
velocity.max =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">2</span>]][<span class="dv">2</span>]
velocity.min =<span class="st"> </span>m<span class="op">$</span>state.space.bounds[[<span class="dv">2</span>]][<span class="dv">1</span>]
position.scale =<span class="st"> </span>n.tilings <span class="op">/</span><span class="st"> </span>(position.max <span class="op">-</span><span class="st"> </span>position.min)
velocity.scale =<span class="st"> </span>n.tilings <span class="op">/</span><span class="st"> </span>(velocity.max <span class="op">-</span><span class="st"> </span>velocity.min)

preprocessState =<span class="st"> </span><span class="cf">function</span>(state) {
  <span class="co"># scale state observation</span>
  state =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(position.scale <span class="op">*</span><span class="st"> </span>state[<span class="dv">1</span>], velocity.scale <span class="op">*</span><span class="st"> </span>state[<span class="dv">2</span>]), <span class="dt">ncol =</span> <span class="dv">2</span>)
  <span class="co"># get active tiles</span>
  active.tiles =<span class="st"> </span><span class="kw"><a href="reference/tilecoding.html">tiles</a></span>(iht, <span class="dv">8</span>, state)
  <span class="co"># return n hot vector with 1 at the position of each active tile</span>
  <span class="kw"><a href="reference/nHot.html">nHot</a></span>(active.tiles, max.size)
}

<span class="kw">set.seed</span>(<span class="dv">123</span>)
res =<span class="st"> </span><span class="kw"><a href="reference/qSigma.html">qlearning</a></span>(m, <span class="dt">fun.approx =</span> <span class="st">"linear"</span>, 
  <span class="dt">preprocessState =</span> preprocessState, <span class="dt">n.episodes =</span> <span class="dv">20</span>)
<span class="kw">print</span>(res<span class="op">$</span>steps)
<span class="co">#&gt;  [1] 1211 2114 2650 3070 3476 3717 3958 4197 4430 4662 4866 5107 5301 5536</span>
<span class="co">#&gt; [15] 5769 5936 6134 6299 6533 6695</span></code></pre></div>
<hr>
</div>
<div id="vignettes" class="section level3">
<h3 class="hasAnchor">
<a href="#vignettes" class="anchor"></a>Vignettes</h3>
<p>Also have a look at the vignettes for further examples.</p>
<ul>
<li><a href="https://markdumke.github.io/reinforcelearn/articles/environments.html">How to create an environment?</a></li>
<li><a href="https://markdumke.github.io/reinforcelearn/articles/algorithms.html">How to solve an environment?</a></li>
</ul>
<hr>
<p>Logo is a modification of <a href="https://www.r-project.org/logo/" class="uri">https://www.r-project.org/logo/</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2 class="hasAnchor">
<a href="#sidebar" class="anchor"></a>Links</h2>
<ul class="list-unstyled">
<li>Report a bug at <br><a href="https://github.com/markdumke/reinforcelearn/issues">https://â€‹github.com/â€‹markdumke/â€‹reinforcelearn/â€‹issues</a>
</li>
</ul>
<h2>License</h2>
<p><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file <a href="LICENSE.html">LICENSE</a></p>
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Markus Dumke <br><small class="roles"> Author, maintainer </small> </li>
</ul>
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://travis-ci.org/markdumke/reinforcelearn"><img src="https://travis-ci.org/markdumke/reinforcelearn.svg?branch=master" alt="Travis-CI Build Status"></a></li>
<li><a href="https://cran.r-project.org/package=reinforcelearn"><img src="http://www.r-pkg.org/badges/version/reinforcelearn" alt="CRAN_Status_Badge"></a></li>
<li><a href="https://codecov.io/github/markdumke/reinforcelearn?branch=master"><img src="https://img.shields.io/codecov/c/github/markdumke/reinforcelearn/master.svg?maxAge=600" alt="Coverage Status"></a></li>
</ul>
</div>

</div>


      <footer><div class="copyright">
  <p>Developed by Markus Dumke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
