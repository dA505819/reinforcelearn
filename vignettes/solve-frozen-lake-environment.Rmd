---
title: "Solve Frozen Lake Environment using Q-Learning"
author: "Markus Dumke"
date: "`r Sys.Date()`"
output:rmarkdown::html_vignette:
fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
## Frozen Lake Environment
  
The Frozen Lake environment is a simple reinforcement learning problem
from [OpenAI Gym](https://gym.openai.com/envs/FrozenLake-v0). 
Starting in a start state, the goal is to reach a goal state 
while traversing a grid. Possible actions include going left, right, up and down. 
If an action would take you off the grid the state is not changed.
Because the ice is slippery there is a stochastic component, so an action might 
take you to a state next to the state you wanted to reach.

<div class="figure">
<img src="frozenlake.jpg"/>
<p class="caption">FrozenLake environment</p>
</div>

## Q-Learning

Q-Learning is an off-policy control algorithm using temporal-difference learning. Given a state and action pair the next state $S'$ and Reward $R$ are sampled from the environment. Then we take the max of the Q values of all possible successor actions. The action value of $S$ and $A$ is then updated towards the observed reward plus a discounted (discount factor $\gamma$) Q value of the next state $S'$ and best action $a$.

The update equation is: 

$Q(S, A) \leftarrow  Q(S, A) + \alpha[R + \gamma \max_a(Q(S', a)) - Q(S, A)]$

In the following we will solve the Frozen Lake problem, i.e. find the shortest path from the start state to the goal state. 

We will use the Gym implementation of the FrozenLake environment. Therefore we need to install python and gym-http-api first. Then we can load the `reinforcelearn` package and create the environment. First we need to set the path to the gym-http-api folder.

```{r, eval = FALSE}
library(reinforcelearn)
options(gym.api.path = "C:/Users/M/Downloads/WinPython-64bit-3.6.0.1Qt5/scripts/gym-http-api")
FrozenLake = makeEnvironment("FrozenLake-v0")
```

Then we can apply Q-Learning to find the optimal action value function $Q$.

```{r, results = "hide", eval = FALSE}
n.episodes = 1000
res = qlearning(FrozenLake, n.episodes = n.episodes)
Q = res$Q
```

Then we can find the optimal policy by acting greedily with respect to $Q$.

```{r, eval = FALSE}
optimal.policy = max.col(Q)
```
Plot $Q_\pi$.

We can plot the average reward of 100 subsequent episodes. The Frozen Lake 
environment is considered o be solved when the average reward of 100 subsequent episodes 
is greater than 0.78. The optimal value is 0.8196.

```{r, eval = FALSE}
plot(x = seq_len(n.episodes), y = res$rewards.per.episode / 1:n.episodes, 
  type = "l", xlim = c(0, 10000), ylab = "Average Reward", xlab = "Episode", 
  main = "Average Reward of all episodes up to now")
```

## More Reinforcement Learning in R:

Learn more about reinforcement learning in R: [reinforcelearn](https://github.com/markdumke/reinforcelearn)

## Bibliography

[Sutton and Barto (2017)](https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf)
[OpenAI Gym](https://gym.openai.com/envs/FrozenLake-v0)
